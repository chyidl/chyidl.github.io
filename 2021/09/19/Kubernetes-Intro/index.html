

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="chyi">
  <meta name="keywords" content="">
  
    <meta name="description" content="Kubernetes">
<meta property="og:type" content="article">
<meta property="og:title" content="Kubernetes Intro">
<meta property="og:url" content="http://chyidl.github.io/2021/09/19/Kubernetes-Intro/">
<meta property="og:site_name" content="Stay Hungry Stay Foolish">
<meta property="og:description" content="Kubernetes">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://chyidl.github.io/misc/images/kubernetes-global-articture.png">
<meta property="og:image" content="http://chyidl.github.io/misc/images/kubernetes-pod-road-map.png">
<meta property="og:image" content="http://chyidl.github.io/misc/images/container_evolution.svg">
<meta property="og:image" content="http://chyidl.github.io/misc/images/components-of-kubernetes.svg">
<meta property="og:image" content="http://chyidl.github.io/misc/images/kubernetes-storageclass.png">
<meta property="og:image" content="http://chyidl.github.io/misc/images/kubernetes-cni-architecture.png">
<meta property="og:image" content="http://chyidl.github.io/misc/images/kube-proxy-userspace-mode.png">
<meta property="og:image" content="http://chyidl.github.io/misc/images/kube-proxy-iptables-mode.png">
<meta property="og:image" content="http://chyidl.github.io/misc/images/vxlan-architecture.png">
<meta property="og:image" content="http://chyidl.github.io/misc/images/kubernetes-pod-infra.png">
<meta property="og:image" content="http://chyidl.github.io/misc/images/kubernetes-rollmap.jpg">
<meta property="article:published_time" content="2021-09-19T14:11:16.000Z">
<meta property="article:modified_time" content="2021-09-19T14:11:16.000Z">
<meta property="article:author" content="chyi">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://chyidl.github.io/misc/images/kubernetes-global-articture.png">
  
  
  <title>Kubernetes Intro - Stay Hungry Stay Foolish</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"chyidl.github.io","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Stay Hungry Stay Foolish" type="application/atom+xml">
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Kubernetes Intro">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-09-19 22:11" pubdate>
        2021年9月19日 晚上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      30k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      248 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Kubernetes Intro</h1>
            
            <div class="markdown-body">
              <h1 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h1><span id="more"></span>

<h2 id="容器基础"><a href="#容器基础" class="headerlink" title="容器基础"></a>容器基础</h2><blockquote>
<p>容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创建出一个“边界”<br>容器，其实是一种特殊的单进程模型而已<br>同一台机器上的所有容器，都共享宿主机操作系统的内核</p>
</blockquote>
  <figure class="highlight perl"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><pre><code class="hljs perl"><span class="hljs-comment"># Cgroups技术用来限制</span><br><span class="hljs-comment"># Namespace技术则是用隔离</span><br>  - Mount Namespace 跟其他Namespace使用略有不同，它对容器进程视图的改变一定是伴随着挂载操作mount才能生效<br>  - <span class="hljs-keyword">chroot</span> (change root file <span class="hljs-keyword">system</span>): 改变进程的根目录到指定位置<br><span class="hljs-comment"># rootfs 根文件系统 (不包括系统内核)</span><br>  &gt; 由于rootfs里打包的不只是应用，而是整个操作系统的文件和目录 (对于一个应用来说，操作系统本身才是它圆形所需要的最完整的<span class="hljs-string">&quot;依赖库&quot;</span>)<br>  - pivot_root<br>  - <span class="hljs-keyword">chroot</span><br></code></pre></td></tr></table></figure>
<ul>
<li><p>Cgroups</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># Linux Cgroups是Linux内核中用来为进程设置资源限制的一个重要功能</span><br><span class="hljs-comment"># Linux Cgroups全称 Linux Control Group,主要作用就是限制进程组能够使用的资源上限，CPU、内存、磁盘、网络带宽</span><br><br>➜ mount -t cgroup<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,name=systemd)<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>rdma type cgroup (rw,nosuid,nodev,noexec,relatime,rdma)<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)                        -- 为块设备设置I/O限制，一般用于磁盘等设备<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/m</span>emory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)                      -- 为进程设置内存使用限制<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)                      -- 为进程分配单独的CPU核和对应的内存节点<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)<br>cgroup on <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)<br><br>➜ ls  <span class="hljs-regexp">/sys/</span>fs<span class="hljs-regexp">/cgroup/</span>cpu<br>cgroup.clone_children  cpuacct.usage             cpuacct.usage_percpu_user  cpu.cfs_quota_us  init.scope         system.slice<br>cgroup.procs           cpuacct.usage_all         cpuacct.usage_sys          cpu.shares        kubepods.slice     tasks<br>cgroup.sane_behavior   cpuacct.usage_percpu      cpuacct.usage_user         cpu.stat          notify_on_release  user.slice<br>cpuacct.stat           cpuacct.usage_percpu_sys  cpu.cfs_period_us          docker            release_agent<br></code></pre></td></tr></table></figure></li>
<li><p>Docker vs Hypervisor</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">1.</span> 用户运行在容器里的应用进程根宿主主机上的其他进程一样，都由宿主主机操作系统同一管理，只不过这些被隔离的进程拥有额外设置过的Namesapce参数, 而Docker项目在这里扮演的角色更多的是旁路式的辅助和管理工作<br><span class="hljs-bullet">2.</span> Hypervisor虚拟化作为应用沙盒，必须由Hypervisor负责创建虚拟机，这个虚拟机真实存在，并且运行完整的GuestOS才能执行用户的应用进程.<br></code></pre></td></tr></table></figure></li>
<li><p>容器化</p>
<figure class="highlight node-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs node-repl"> &gt; Dockerd实际上是在创建容器进程时，指定进程所需要启动的一组Namespace参数，这样，容器只能“看”到当前Namespace所限定的资源、文件、设备、状态、或配置，而对于宿主机以及其他不相关的程序，就完全看不到<br><span class="hljs-meta">&gt;</span> <span class="javascript"><span class="hljs-string">&quot;敏捷&quot;</span>和<span class="hljs-string">&quot;高性能&quot;</span>是容器相较于虚拟机最大的优势，也是它能够在PaaS这种更细粒度的资源管理平台上大行其道的重要原因.</span><br><br>- 容器和应用的同生命周期<br></code></pre></td></tr></table></figure></li>
<li><p>Docker镜像</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> Docker镜像的设计中引入层layer,用户制作镜像的每一步操作都会生成一个层，也就是一个增量rootfs</span><br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash"> Union File System 联合文件系统</span><br><span class="hljs-meta">  &gt;</span><span class="bash"> 将多个不同位置的目录联合挂在(Union mount)到同一个目录下</span><br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash"> overlay2</span><br><span class="hljs-meta">  &gt;</span><span class="bash"> overlay2, <span class="hljs-built_in">which</span> has potential performance advantages over the aufs storage driver.</span><br></code></pre></td></tr></table></figure></li>
<li><p>容器</p>
<blockquote>
<p>是由Linux Namespace、Linux Cgroups和rootfs第三种技术构建出来的进程隔离环境</p>
</blockquote>
</li>
<li><p>Linux容器</p>
<figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs vala"><span class="hljs-meta"># 容器镜像 - 静态视图</span><br>  &gt; 一组联合rootfs<br><br><span class="hljs-meta"># 容器运行时 - 动态视图</span><br>  &gt; 一组Namespace + Cgroups 构成的隔离环境<br><br><span class="hljs-meta"># 容器编排工具:</span><br>  - Docker: Compose+Swarm<br>  - Google+ReadHat: Kubernetes<br></code></pre></td></tr></table></figure></li>
<li><p>Kubernetes全局架构<br><img src="/misc/images/kubernetes-global-articture.png" srcset="/img/loading.gif" lazyload alt="Kubernetes 全局架构"></p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">-</span> Master(控制节点):<br>  &gt; 如何编排、管理、调度用户提交的作业<br><span class="hljs-bullet">  -</span> kube-controller-manager: Controller Manager<br><span class="hljs-bullet">  -</span> kube-apiserver: API Server (整个集群的持久化数据由kube-apiserver处理后保存在Etcd中)<br><span class="hljs-bullet">  -</span> kube-scheduler: Scheduler<br><br><span class="hljs-bullet">-</span> Node(计算节点):<br><span class="hljs-bullet">  -</span> kubelet: kubelet主要责任同容器运行时(docker)交互<br><span class="hljs-bullet">  -</span> CNI : kubelet + Networking - 网络插件为容器配置网络<br><span class="hljs-bullet">  -</span> CRI : kubectl + Container Runtime Interface (接口定义容器运行时的各项核心操作)<br><span class="hljs-bullet">  -</span> CSI : kubectl + Volume Plugin - 存储插件为容器持久化存储<br><span class="hljs-bullet">  -</span> OCI : Container Runtime Interface (容器运行时规范同底层Linux操作系统进行交互, 即将CRI请求翻译成Linux系统操作调用 Namespace + Cgroups)<br><span class="hljs-bullet">  -</span> grpc: kubelet + Device Plugin (Kubernetes项目管理宿主主机物理设备的主要组件)<br><br><span class="hljs-quote">&gt; Kubernetes项目关心解决的问题是&quot;运行在大规模集群中的各种任务之间，实际上存在着各种各样的关系，这些关系的处理，才是作业编排和管理系统最困难的地方&quot;</span><br></code></pre></td></tr></table></figure></li>
<li><p>Kubernetes 核心功能<br><img src="/misc/images/kubernetes-pod-road-map.png" srcset="/img/loading.gif" lazyload alt="Kubernetes 核心功能"></p>
<figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs vala">&gt; Kubernetes项目的本质是为用户提供一个具有普遍意义的容器编排工具<br><br><span class="hljs-meta"># Pod:</span><br>  &gt; Pod里的容器共享同一个Network Namespace,同一组数据卷，从而达到高效交换信息的目的<br>  &gt; Pod就是Kubenetes世界里的<span class="hljs-string">&quot;应用&quot;</span>,而一个应用，可以由多个容器组成<br><br><span class="hljs-meta"># Service:</span><br>  &gt; Service服务作为Pod代理入口(Portal)从而代替Pod对外暴露一个固定的网络地址<br><br><span class="hljs-meta"># Deployment:</span><br>  &gt; Pod多实例管理器<br><br><span class="hljs-meta"># Secret:</span><br>  &gt; Secret对象是保存在Etcd里的键值对数据<br><br><span class="hljs-meta"># Job:</span><br>  &gt; 描述一次性运行Pod<br><br><span class="hljs-meta"># CronJob:</span><br>  &gt; 描述定时任务<br><br><span class="hljs-meta"># DaemonSet:</span><br>  &gt; 描述每个宿主机上必须且只能运行一个副本的守护进程服务<br><br><br><span class="hljs-meta"># 编排对象 - 描述管理的应用</span><br>  - Pod<br>  - Job<br>  - CronJob<br><br><span class="hljs-meta"># 服务对象 - 负责平台级功能</span><br>  - Service<br>  - Secret<br>  - Horizontal Pod Autoscaler(自动水平扩展器)<br><br><span class="hljs-meta"># 声明式API</span><br>  &gt; 这种API对应的<span class="hljs-string">&quot;编排对象&quot;</span>和<span class="hljs-string">&quot;服务对象&quot;</span>都是Kubernetes项目中的API对象(API <span class="hljs-built_in">Object</span>)<br></code></pre></td></tr></table></figure></li>
</ul>
<h2 id="Kubernetes-概念"><a href="#Kubernetes-概念" class="headerlink" title="Kubernetes 概念"></a>Kubernetes 概念</h2><ul>
<li>概述<ul>
<li>Kubernetes是什么<br><img src="/misc/images/container_evolution.svg" srcset="/img/loading.gif" lazyload alt="容器演进过程"><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-quote">&gt; Kubernetes 是一个可移植的，可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化.</span><br><span class="hljs-quote">&gt; Kubernetes源于希腊语,意为&quot;舵手&quot;或&quot;飞行员&quot;</span><br><span class="hljs-quote">&gt; Kubernetes建立在Google在大规模运行生产工作负载方面拥有十几年的经验的基础上，结合社区中最好的想法和实践.</span><br><br><span class="hljs-section"># 传统部署时代:</span><br><span class="hljs-bullet">  -</span> 资源分配问题<br><br><span class="hljs-section"># 虚拟化部署时代:</span><br><span class="hljs-bullet">  -</span> 虚拟化技术允许在单个物理服务器的CPU上运行多个虚拟机VM,虚拟化允许应用程序在VM之间隔离,并提供一定成都的安全，因为一个应用程序的信息不能被另一个应用程序随意访问<br><span class="hljs-bullet">  -</span> 虚拟化技术能够更好的利用物理服务器上的资源，因为可轻松地添加或更新应用程序而可以实现更好的可伸缩性，降低硬件成本<br><span class="hljs-bullet">  -</span> 每一个VM是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统<br><br><span class="hljs-section"># 容器部署时代:</span><br><span class="hljs-bullet">  -</span> 容器类似于VM，但是具有被放宽的隔离属性，可以在应用程序之间共享操作系统OS<br><span class="hljs-bullet">  -</span> 容器与VM具有自己的文件系统、CPU、内存、进程空间<br><span class="hljs-bullet">  -</span> 容器的好处:<br><span class="hljs-bullet">    -</span> 敏捷应用程序的创建和部署: 与使用VM镜像相比，提高容器镜像创建的便捷性和效率<br><span class="hljs-bullet">    -</span> 持续开发、集成和部署: 通过快速简单的回滚(由于镜像不可变性)，支持可靠且频繁的容器镜像构建和部署<br><span class="hljs-bullet">    -</span> 开发与运维的分离: 在构建/发布时而不是在部署时创建应用程序容器镜像,从而将应用程序于基础架构分离<br><span class="hljs-bullet">    -</span> 可观察性: 显示操作系统级别的信息和指标，显示应用程序的运行状态和其他指标信号<br><span class="hljs-bullet">    -</span> 跨开发、测试和生产的环境一致性: 在便携计算机上与云中相同地运行<br><span class="hljs-bullet">    -</span> 跨云和操作系统发型版本的可移植性: 可在Ubuntu,RHEL,CoreOS,本地<br><span class="hljs-bullet">    -</span> 以应用程序为中心的管理: 提高抽象级别，从在虚拟硬件上运行OS到使用逻辑资源在OS上运行应用程序<br><span class="hljs-bullet">    -</span> 松散耦合、分布式、弹性、解放的微服务: 应用程序被分解成较小的独立部分，并且可以动态部署和管理-而不是在一台大型单机上整体运行<br><span class="hljs-bullet">    -</span> 资源隔离: 可预测的应用程序性能<br><span class="hljs-bullet">    -</span> 资源利用: 高效率和高密度<br><br><span class="hljs-section"># Kubernetes 提供功能:</span><br><span class="hljs-bullet">  -</span> 服务发现和负载均衡<br><span class="hljs-bullet">  -</span> 存储编排<br><span class="hljs-bullet">  -</span> 自动部署和回滚:<br><span class="hljs-bullet">  -</span> 自动完成装箱计算:<br><span class="hljs-code">    &gt; Kubernetes 允许指定每个容器所需CPU和内存RAM 当容器指定资源请求时，Kubernetes可以做出更好的决策来管理容器资源</span><br><span class="hljs-code">  - 自我修复</span><br><span class="hljs-code">  - 密钥与配置管理:</span><br><span class="hljs-code">    &gt; Kubernetes存储和管理敏感信息</span><br><span class="hljs-code"></span><br><span class="hljs-section"># Kubernetes 不提供:</span><br><span class="hljs-bullet">  -</span> 不限制支持的应用程序类型: Kubernetes支持及其多种多样的工作负载，包括无状态、有状态和数据处理工作负载。如果应用程序可以在容器中运行，那么他应该可以在Kubernetes上很好的运行.<br><span class="hljs-bullet">  -</span> 不部署源代码，也不构建应用: 持续集成CI、交付和部署CI/CD工作流<br><span class="hljs-bullet">  -</span> 不提供应用程序级别的服务作为内置服务<br><span class="hljs-bullet">  -</span> 不提供日志记录、监控或报警解决方案: 提供一些集成作为概念证明并提供收集和到处指标的机制<br><span class="hljs-bullet">  -</span> 不提供不采用任何全面的机器配置、维护、管理或自我修复系统<br><br><span class="hljs-quote">&gt; Kubernetes 不仅仅是一个编排系统，实际上消除了编排的需要，编排的技术定义是执行已定义的工作流程，首先执行A，然后执行B，在执行C，Kubernetes包含一组独立的，可组合的控制过程，这些过程联系地将当前状态驱动到所提供状态，如何从A到C的方式无关紧要，也不需要几种控制，使得系统更易于使用且功能更强大、系统更健壮、更为弹性和扩展性.</span><br></code></pre></td></tr></table></figure></li>
<li>Kubernetes 组件<br><img src="/misc/images/components-of-kubernetes.svg" srcset="/img/loading.gif" lazyload alt="Kubernetes关联组件"><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section"># Control Plane Compoenents 控制平面组件</span><br>  &gt; 控制平面组件对集群做出全局决策(调度),以及检测和响应集群事件<br>  &gt; 控制平面组件可以在集群中的任何节点上运行<br><br><span class="hljs-bullet">  -</span> kube-apiserver:<br><span class="hljs-code">    &gt; 该组件公开Kubernetes API, API服务器是Kubernetes控制面的前端</span><br><span class="hljs-code">    &gt; 运行kube-apiserver多个实例并在这些实例之间平衡流量</span><br><span class="hljs-code"></span><br><span class="hljs-bullet">  -</span> etcd:<br><span class="hljs-code">    &gt; etcd 是兼顾一致性和高可用性的键值数据库,作为保存Kubernetes所有集群数据的后台数据库</span><br></code></pre></td></tr></table></figure></li>
<li>PV、PVC、StorageClass<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section"># Kubernetes 容器持久化存储</span><br><span class="hljs-bullet">  -</span> PV: 持久化存储的实现<br><span class="hljs-code">    &gt; 持久化存储数据卷,定义的是一个持久化存储在宿主主机上的目录</span><br><span class="hljs-code"></span><br><span class="hljs-bullet">  -</span> PVC: 持久化存储的接口<br><span class="hljs-code">    &gt; 描述的持久化存储的属性 (Volume存储大小,可读写权限)</span><br><span class="hljs-code">    &gt; PVC必须和某个符合条件的PV进行绑定</span><br><span class="hljs-code">      - 1. PV 和 PVC 的spec字段, PV的存储(storage)大小,必须满足PVC的要求</span><br><span class="hljs-code">      - 2. PV 和 PVC 的storageClassName字段必须一样</span><br><span class="hljs-code"></span><br><span class="hljs-bullet">  -</span> Volume Controller: 持久化存储控制器<br><span class="hljs-bullet">    -</span> PersistentVolumeController:<br><span class="hljs-code">      &gt; 不断查看当前每一个PVC是否已经处于Bound状态,如果不是，就会遍历所有的、可用的PV,尝试将其PVC进行绑定</span><br><span class="hljs-code"></span><br><span class="hljs-section"># 持久化Volume</span><br><span class="hljs-bullet">  -</span> 远程文件存储<br><span class="hljs-bullet">    -</span> NFS<br><span class="hljs-bullet">    -</span> GlusterFS<br><span class="hljs-bullet">  -</span> 远程快存储<br><span class="hljs-bullet">    -</span> 公有云提供的远程磁盘<br><br><span class="hljs-section"># 准备&quot;持久化&quot;宿主机目录</span><br><span class="hljs-bullet">  -</span> 第一阶段 (Attch) -- nodeName<br><span class="hljs-code">    &gt; 默认情况下，kubelet 为 Volume创建的目录是 /var/lib/kubelet/pods/&lt;Pod的ID&gt;/volumes/kubernetes.io-&lt;Volume类型&gt;/&lt;Volume名字&gt;</span><br><span class="hljs-code">    &gt; AttachDetachController (运行在Master节点上)</span><br><span class="hljs-code"></span><br><span class="hljs-bullet">  -</span> 第二阶段 (Mount) -- dir<br><span class="hljs-code">    &gt; 格式化磁盘设备,然后将其挂在到宿主机指定的挂载点上</span><br><span class="hljs-code">    &gt; VolumeManagerReconciler (运行在Node节点上,是一个独立于kubelet主循环的goroutine)</span><br><span class="hljs-code"></span><br><span class="hljs-section"># StorageClass:</span><br>  &gt; Kubernetes 提供一套可以自动创建PV的机制，Dynamic Provisioning<br>  &gt; 手动创建PV的方式叫做 Staic Provisioning<br>  &gt; StorageClass的作用就是创建PV的模板<br><span class="hljs-bullet">  -</span> 1. PV的属性 (存储类型、Volume大小)<br><span class="hljs-bullet">  -</span> 2. 创建PV需要用到的存储插件(Ceph, NFS)<br>  &gt; Kubernetes根据用户提交的PVC，找到对应的StorageClass,然后调用该StorageClass声明的存储插件，创建出需要的PV<br></code></pre></td></tr></table></figure>
<img src="/misc/images/kubernetes-storageclass.png" srcset="/img/loading.gif" lazyload alt="StorageClass 流程"><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner">搭建StorageClass + NFS</a><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs routeros">1. 创建一个可用的NFS<span class="hljs-built_in"> Server</span><br><span class="hljs-built_in"></span>  IP: 172.30.1.14<br>  <span class="hljs-builtin-name">Export</span> PATH: /export/K8sData/<br><br>  $ sudo apt-<span class="hljs-builtin-name">get</span> install nfs-common cifs-utils<br><br>2. 创建Service Account. 管控NFS Provisioner在K8s集群中运行的权限<br><br>3. 创建StorageClass.负责建立PVC并调用NFS provisioner进行预定的工作，并让PV与PVC建立管理<br>4. 创建NFS Provisioner,在NFS共享目录下创建挂载点(volume),建立PV并将PV与NFS的挂在点建立关联<br><br></code></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="部署Kubernetes"><a href="#部署Kubernetes" class="headerlink" title="部署Kubernetes"></a>部署Kubernetes</h2><ul>
<li><p>kubeadm</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section"># 创建一个Master节点</span><br>$ kubeadm init<br><br><span class="hljs-section"># 将一个Node节点加入当前集群</span><br>$ kubeadm join <span class="xml">&lt;Master节点的IP和端口&gt;</span><br><br><span class="hljs-section"># kubeadm 工作原理</span><br><span class="hljs-bullet">  -</span> kubelet 是Kubernetes项目用来操作Docker等容器运行时的核心组件,除了跟容器运行时交互外，kubelet在配置容器网络、管理容器数据卷时，都需要直接操作宿主机.<br>  &gt; Kubeadm选择一种妥协方案，把kubelet直接运行在宿主机上，然后使用容器部署其他的Kubernetes组件.<br><br><span class="hljs-section"># kubeadm init工作流程</span><br><span class="hljs-bullet">  -</span> 1. Preflight Checks 检查工作, 确定机器可以用来部署Kubernetes<br><span class="hljs-bullet">    -</span> Linux Kernal必须&gt;= 3.10<br><span class="hljs-bullet">    -</span> Linux Cgroups 模块是否可用<br><span class="hljs-bullet">    -</span> 机器的hostname是否标准<br><span class="hljs-bullet">    -</span> 安装的kubeadm和kubelet版本是否匹配<br><span class="hljs-bullet">    -</span> 机器上是不是已经安装Kubernetes二进制文件<br><span class="hljs-bullet">    -</span> Kubernetes工作端口10250/10251/10252端口是否占用<br><span class="hljs-bullet">    -</span> ip, mount Linux指令是否存在<br><span class="hljs-bullet">    -</span> docker是否安装<br><span class="hljs-bullet">  -</span> 2. 生成 kubernetes对外提供服务所需要的各种证书和目录<br><span class="hljs-bullet">    -</span> Kubernetes对外提供服务时，除非专门开启&quot;不安全模式&quot;,否则都要通过HTTPS才能访问kube-apiserver,需要kubernetes集群配置证书文件<br><span class="hljs-bullet">    -</span> /etc/kubernetes/pki (kubeadm为kubernetes项目生成的证书文件)<br><span class="hljs-bullet">  -</span> 3. kubeadm为其他组件生成访问kube-apiserver所需的配置文件<br><span class="hljs-bullet">    -</span> /etc/kubernetes/xxx.cnf<br><span class="hljs-bullet">  -</span> 4. kubeadm为Master组件生成Pod配置文件<br><span class="hljs-bullet">    -</span> kube-apiserver<br><span class="hljs-bullet">    -</span> kube-controller-manager<br><span class="hljs-bullet">    -</span> kube-scheduler<br><span class="hljs-bullet">    -</span> ETCD<br><span class="hljs-code">    &gt; 在Kubernetes中，特殊的容器启动方法&quot;Static Pod&quot;,允许把要部署的Pod的YAML文件放在一个指定的目录里，当kubelet启动时会自动检查次目录，加载所有的PodYAML文件</span><br><span class="hljs-code">  - 5. kubeadm检查localhost:6443/healthz 等待Master组件完全运行起来</span><br><span class="hljs-code">  - 6. kubeadm为集群生成一个bootstrap token.</span><br><span class="hljs-code">    - 剩余的Node节点可以通过此token加入到集群中</span><br><span class="hljs-code">  - 7. 安装插件kube-proxy和DNS</span><br><span class="hljs-code">    - kube-proxy: 集群的服务发现</span><br><span class="hljs-code">    - DNS:</span><br><span class="hljs-code"></span><br><span class="hljs-section"># kubeadm join工作流程</span><br><span class="hljs-bullet">  -</span> bootstrap token<br><span class="hljs-code">    &gt; kubeadm至少需要发起一次&quot;不安全模式&quot;的访问kube-apiserver,从而拿到保存在ConfigMap中的cluster-info(保存了APIServer的授权信息),而bootstrap token扮演的就是这个过程中的安全验证角色</span><br><span class="hljs-code"></span><br><span class="hljs-section"># kubeadm部署参数配置文件(kubeadm.yaml)</span><br>  $ kubeadm init --config kubeadm.yaml<br></code></pre></td></tr></table></figure></li>
<li><p>installing kubeadm, kubelet and kubectl</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">- kubeadm: the command <span class="hljs-keyword">to</span> bootstrap the <span class="hljs-keyword">cluster</span><br>- kubelet: the component that runs <span class="hljs-keyword">on</span> <span class="hljs-keyword">all</span> <span class="hljs-keyword">of</span> the machines <span class="hljs-keyword">in</span> your <span class="hljs-keyword">cluster</span> <span class="hljs-keyword">and</span> does things <span class="hljs-keyword">like</span> starting pods <span class="hljs-keyword">and</span> containers.<br>- kubectl: the command <span class="hljs-type">line</span> util <span class="hljs-keyword">to</span> talk <span class="hljs-keyword">to</span> your <span class="hljs-keyword">cluster</span><br></code></pre></td></tr></table></figure></li>
<li><p>container runtimes</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs vim"># common container <span class="hljs-keyword">runtime</span><span class="hljs-variable">s:</span><br>  - containerd<br>  - CRI-O<br>  - Docker<br><br># Cgroup(Control groups) driver<span class="hljs-variable">s:</span><br>  &gt; used <span class="hljs-keyword">to</span> constrain(限制) resources that are allocated <span class="hljs-keyword">to</span> processes.<br>  &gt; Changing the settings such that your container <span class="hljs-keyword">runtime</span> <span class="hljs-built_in">and</span> kubelet use systemd <span class="hljs-keyword">as</span> the cgroup stabilized the <span class="hljs-built_in">system</span>.<br><br># Cgroup V2<br>  &gt; <span class="hljs-keyword">is</span> the <span class="hljs-keyword">next</span> <span class="hljs-keyword">version</span> of cgroup Linux API.<br>  - cleaner <span class="hljs-built_in">and</span> easier <span class="hljs-keyword">to</span> use API<br>  - safe sub-tree delegation <span class="hljs-keyword">to</span> containers<br>  - newer features like Pressure Stall Information<br><br># Migrating <span class="hljs-keyword">to</span> the systemd driver in kubeadm managed clusters<br>  - Docker:<br>    sudo <span class="hljs-built_in">mkdir</span> /etc/docker<br>    <span class="hljs-keyword">cat</span> &lt;&lt;EOF | sudo tee /etc/docker/daemon.json<br>    &#123;<br>      <span class="hljs-string">&quot;exec-opts&quot;</span>: [<span class="hljs-string">&quot;native.cgroupdriver=systemd&quot;</span>],<br>      <span class="hljs-string">&quot;log-driver&quot;</span>: <span class="hljs-string">&quot;json-file&quot;</span>,<br>      <span class="hljs-string">&quot;log-opts&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;max-size&quot;</span>: <span class="hljs-string">&quot;100m&quot;</span><br>      &#125;,<br>      <span class="hljs-string">&quot;storage-driver&quot;</span>: <span class="hljs-string">&quot;overlay2&quot;</span><br>    &#125;<br>    EOF<br><br>  - Restart Docker <span class="hljs-built_in">and</span> enable <span class="hljs-keyword">on</span> boo<span class="hljs-variable">t:</span><br>    sudo systemctl enable docker<br>    sudo systemctl daemon-reload<br>    sudo systemctl restart docker<br></code></pre></td></tr></table></figure></li>
<li><p>kubeadm部署</p>
<blockquote>
<p>kubeadm目前欠缺部署高可用Kubernetes集群,ETCD、Master组件都应该是多节点集群</p>
</blockquote>
</li>
</ul>
  <figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><code class="hljs stata"> # 创建一个Master节点 (--image-repository指定容器镜像地址使用阿里云)<br> ➜ sudo kubeadm init [--image-repository=&#x27;registry.cn-hangzhou.aliyuncs.com/google_containers&#x27;]<br> [init] Using Kubernetes <span class="hljs-keyword">version</span>: v1.22.2<br> [preflight] Running pre-flight checks<br> [preflight] Pulling images required <span class="hljs-keyword">for</span> setting up a Kubernetes <span class="hljs-keyword">cluster</span><br> [preflight] This might take a minute or <span class="hljs-keyword">two</span>, depending <span class="hljs-keyword">on</span> the speed of your internet connection<br> [preflight] You can also perform this action <span class="hljs-keyword">in</span> beforehand using &#x27;kubeadm config images pull&#x27;<br> [certs] Using certificateDir folder <span class="hljs-string">&quot;/etc/kubernetes/pki&quot;</span><br> [certs] Generating <span class="hljs-string">&quot;ca&quot;</span> certificate and key<br> [certs] Generating <span class="hljs-string">&quot;apiserver&quot;</span> certificate and key<br> [certs] apiserver serving cert is signed <span class="hljs-keyword">for</span> DNS names [chyiyaqing-poweredge-r720 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.<span class="hljs-keyword">cluster</span>.<span class="hljs-keyword">local</span>] and IPs [10.96.0.1 192.168.50.57]<br> [certs] Generating <span class="hljs-string">&quot;apiserver-kubelet-client&quot;</span> certificate and key<br> [certs] Generating <span class="hljs-string">&quot;front-proxy-ca&quot;</span> certificate and key<br> [certs] Generating <span class="hljs-string">&quot;front-proxy-client&quot;</span> certificate and key<br> [certs] Generating <span class="hljs-string">&quot;etcd/ca&quot;</span> certificate and key<br> [certs] Generating <span class="hljs-string">&quot;etcd/server&quot;</span> certificate and key<br> [certs] etcd/server serving cert is signed <span class="hljs-keyword">for</span> DNS names [chyiyaqing-poweredge-r720 localhost] and IPs [192.168.50.57 127.0.0.1 ::1]<br> [certs] Generating <span class="hljs-string">&quot;etcd/peer&quot;</span> certificate and key<br> [certs] etcd/peer serving cert is signed <span class="hljs-keyword">for</span> DNS names [chyiyaqing-poweredge-r720 localhost] and IPs [192.168.50.57 127.0.0.1 ::1]<br> [certs] Generating <span class="hljs-string">&quot;etcd/healthcheck-client&quot;</span> certificate and key<br> [certs] Generating <span class="hljs-string">&quot;apiserver-etcd-client&quot;</span> certificate and key<br> [certs] Generating <span class="hljs-string">&quot;sa&quot;</span> key and public key<br> [kubeconfig] Using kubeconfig folder <span class="hljs-string">&quot;/etc/kubernetes&quot;</span><br> [kubeconfig] Writing <span class="hljs-string">&quot;admin.conf&quot;</span> kubeconfig <span class="hljs-keyword">file</span><br> [kubeconfig] Writing <span class="hljs-string">&quot;kubelet.conf&quot;</span> kubeconfig <span class="hljs-keyword">file</span><br> [kubeconfig] Writing <span class="hljs-string">&quot;controller-manager.conf&quot;</span> kubeconfig <span class="hljs-keyword">file</span><br> [kubeconfig] Writing <span class="hljs-string">&quot;scheduler.conf&quot;</span> kubeconfig <span class="hljs-keyword">file</span><br> [kubelet-start] Writing kubelet environment <span class="hljs-keyword">file</span> with flags to <span class="hljs-keyword">file</span> <span class="hljs-string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br> [kubelet-start] Writing kubelet configuration to <span class="hljs-keyword">file</span> <span class="hljs-string">&quot;/var/lib/kubelet/config.yaml&quot;</span><br> [kubelet-start] Starting the kubelet<br> [control-plane] Using manifest folder <span class="hljs-string">&quot;/etc/kubernetes/manifests&quot;</span><br> [control-plane] Creating static Pod manifest <span class="hljs-keyword">for</span> <span class="hljs-string">&quot;kube-apiserver&quot;</span><br> [control-plane] Creating static Pod manifest <span class="hljs-keyword">for</span> <span class="hljs-string">&quot;kube-controller-manager&quot;</span><br> [control-plane] Creating static Pod manifest <span class="hljs-keyword">for</span> <span class="hljs-string">&quot;kube-scheduler&quot;</span><br> [etcd] Creating static Pod manifest <span class="hljs-keyword">for</span> <span class="hljs-keyword">local</span> etcd <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;/etc/kubernetes/manifests&quot;</span><br> [wait-control-plane] Waiting <span class="hljs-keyword">for</span> the kubelet to <span class="hljs-keyword">boot</span> up the control plane <span class="hljs-keyword">as</span> static Pods from directory <span class="hljs-string">&quot;/etc/kubernetes/manifests&quot;</span>. This can take up to 4m0s<br> [apiclient] All control plane components are healthy after 9.004478 seconds<br> [upload-config] Storing the configuration used <span class="hljs-keyword">in</span> ConfigMap <span class="hljs-string">&quot;kubeadm-config&quot;</span> <span class="hljs-keyword">in</span> the <span class="hljs-string">&quot;kube-system&quot;</span> Namespace<br> [kubelet] Creating a ConfigMap <span class="hljs-string">&quot;kubelet-config-1.22&quot;</span> <span class="hljs-keyword">in</span> namespace kube-system with the configuration <span class="hljs-keyword">for</span> the kubelets <span class="hljs-keyword">in</span> the <span class="hljs-keyword">cluster</span><br> [upload-certs] Skipping phase. Please see --upload-certs<br> [<span class="hljs-keyword">mark</span>-control-plane] Marking the node chyiyaqing-poweredge-r720 <span class="hljs-keyword">as</span> control-plane <span class="hljs-keyword">by</span> adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]<br> [<span class="hljs-keyword">mark</span>-control-plane] Marking the node chyiyaqing-poweredge-r720 <span class="hljs-keyword">as</span> control-plane <span class="hljs-keyword">by</span> adding the taints [node-role.kubernetes.io/master:NoSchedule]<br> [<span class="hljs-keyword">bootstrap</span>-<span class="hljs-keyword">token</span>] Using <span class="hljs-keyword">token</span>: z7bgdd.d4lm4cueg5vo9krh<br> [<span class="hljs-keyword">bootstrap</span>-<span class="hljs-keyword">token</span>] Configuring <span class="hljs-keyword">bootstrap</span> tokens, <span class="hljs-keyword">cluster</span>-info ConfigMap, RBAC Roles<br> [<span class="hljs-keyword">bootstrap</span>-<span class="hljs-keyword">token</span>] configured RBAC rules to allow Node <span class="hljs-keyword">Bootstrap</span> tokens to get nodes<br> [<span class="hljs-keyword">bootstrap</span>-<span class="hljs-keyword">token</span>] configured RBAC rules to allow Node <span class="hljs-keyword">Bootstrap</span> tokens to <span class="hljs-keyword">post</span> CSRs <span class="hljs-keyword">in</span> <span class="hljs-keyword">order</span> <span class="hljs-keyword">for</span> nodes to get long term certificate credentials<br> [<span class="hljs-keyword">bootstrap</span>-<span class="hljs-keyword">token</span>] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node <span class="hljs-keyword">Bootstrap</span> <span class="hljs-keyword">Token</span><br> [<span class="hljs-keyword">bootstrap</span>-<span class="hljs-keyword">token</span>] configured RBAC rules to allow certificate rotation <span class="hljs-keyword">for</span> all node client certificates <span class="hljs-keyword">in</span> the <span class="hljs-keyword">cluster</span><br> [<span class="hljs-keyword">bootstrap</span>-<span class="hljs-keyword">token</span>] Creating the <span class="hljs-string">&quot;cluster-info&quot;</span> ConfigMap <span class="hljs-keyword">in</span> the <span class="hljs-string">&quot;kube-public&quot;</span> namespace<br> [kubelet-finalize] Updating <span class="hljs-string">&quot;/etc/kubernetes/kubelet.conf&quot;</span> to point to a rotatable kubelet client certificate and key<br> [addons] Applied essential addon: CoreDNS<br> [addons] Applied essential addon: kube-proxy<br><br> Your Kubernetes control-plane has initialized successfully!<br><br> To start using your <span class="hljs-keyword">cluster</span>, you need to <span class="hljs-keyword">run</span> the following <span class="hljs-keyword">as</span> a regular user:<br><br>   <span class="hljs-keyword">mkdir</span> -p <span class="hljs-variable">$HOME</span>/.kube<br>   sudo cp -i /etc/kubernetes/admin.<span class="hljs-keyword">conf</span> <span class="hljs-variable">$HOME</span>/.kube/config<br>   sudo chown $(id -<span class="hljs-keyword">u</span>):$(id -<span class="hljs-keyword">g</span>) <span class="hljs-variable">$HOME</span>/.kube/config<br><br> Alternatively, <span class="hljs-keyword">if</span> you are the root user, you can <span class="hljs-keyword">run</span>:<br><br>   export KUBECONFIG=/etc/kubernetes/admin.<span class="hljs-keyword">conf</span><br><br> You should now deploy a pod network to the <span class="hljs-keyword">cluster</span>.<br> <span class="hljs-keyword">Run</span> <span class="hljs-string">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> with <span class="hljs-keyword">one</span> of the options listed at:<br>   https:<span class="hljs-comment">//kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><br> Then you can join any number of worker nodes <span class="hljs-keyword">by</span> running the following <span class="hljs-keyword">on</span> each <span class="hljs-keyword">as</span> root:<br><br> kubeadm join 192.168.50.57:6443 --<span class="hljs-keyword">token</span> z7bgdd.d4lm4cueg5vo9krh \<br>--discovery-<span class="hljs-keyword">token</span>-<span class="hljs-keyword">ca</span>-cert-hash sha256:f56091fb52dddc01e552ad110b3479015f4bcdaba5fadec6d76eadab1b3ee48b<br><br> # 将一个Node节点加入当前集群<br> $ kubeadm join &lt;Master节点的IP和端口&gt;<br><br> # 获取kubeadm临时生成的<span class="hljs-keyword">token</span><br> ➜ kubeadm <span class="hljs-keyword">token</span> <span class="hljs-keyword">list</span><br> <span class="hljs-keyword">TOKEN</span>                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS<br> z1ktsy.k2dzz0m17d42nsem   23h         2021-10-15T05:26:51Z   authentication,signing   The default <span class="hljs-keyword">bootstrap</span> <span class="hljs-keyword">token</span> generated <span class="hljs-keyword">by</span> &#x27;kubeadm init&#x27;.   system:bootstrappers:kubeadm:default-node-<span class="hljs-keyword">token</span><br><br> # 查看nodes<br> ➜ kubectl get nodes<br> NAME                        STATUS   ROLES                  AGE     <span class="hljs-keyword">VERSION</span><br> chyiyaqing-poweredge-r720   Ready    control-plane,master   4m49s   v1.22.2<br><br> # 查看Pod运行情况<br> ➜ kubectl get pod -A<br> NAMESPACE     NAME                                                READY   STATUS              RESTARTS   AGE<br> kube-system   coredns-7d89d9b6b8-cch8p                            0/1     ContainerCreating   0          5m10s<br> kube-system   coredns-7d89d9b6b8-vkzw7                            0/1     ContainerCreating   0          5m10s<br> kube-system   etcd-chyiyaqing-poweredge-r720                      1/1     Running             0          5m15s<br> kube-system   kube-apiserver-chyiyaqing-poweredge-r720            1/1     Running             0          5m15s<br> kube-system   kube-controller-manager-chyiyaqing-poweredge-r720   1/1     Running             0          5m17s<br> kube-system   kube-proxy-smnf2                                    1/1     Running             0          5m10s<br> kube-system   kube-scheduler-chyiyaqing-poweredge-r720            1/1     Running             0          5m14s<br><br> # kubectl <span class="hljs-keyword">describe</span> 查看节点详细信息、状态和事件Event<br> ➜ kubectl <span class="hljs-keyword">describe</span> pod coredns-7d89d9b6b8-cch8p -<span class="hljs-keyword">n</span> kube-system<br> Name:                 coredns-7d89d9b6b8-cch8p<br> Namespace:            kube-system<br> Priority:             2000000000<br> Priority <span class="hljs-keyword">Class</span> Name:  system-<span class="hljs-keyword">cluster</span>-critical<br> Node:                 chyiyaqing-poweredge-r720/192.168.50.57<br> Start Time:           Thu, 14 Oct 2021 13:27:02 +0800<br> Labels:               k8s-<span class="hljs-keyword">app</span>=kube-dns<br>                       pod-template-hash=7d89d9b6b8<br> Annotations:          &lt;none&gt;<br> Status:               Pending<br> IP:<br> IPs:                  &lt;none&gt;<br> Controlled <span class="hljs-keyword">By</span>:        ReplicaSet/coredns-7d89d9b6b8<br> Containers:<br>   coredns:<br>     Container ID:<br>     Image:         registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4<br>     Image ID:<br>     Ports:         53/UDP, 53/TCP, 9153/TCP<br>     Host Ports:    0/UDP, 0/TCP, 0/TCP<br>     <span class="hljs-keyword">Args</span>:<br>       -<span class="hljs-keyword">conf</span><br>       /etc/coredns/Corefile<br>     State:          Waiting<br>       Reason:       ContainerCreating<br>     Ready:          False<br>     Restart <span class="hljs-keyword">Count</span>:  0<br>     Limits:<br>       <span class="hljs-keyword">memory</span>:  170Mi<br>     Requests:<br>       cpu:        100m<br>       <span class="hljs-keyword">memory</span>:     70Mi<br>     Liveness:     http-get http:<span class="hljs-comment">//:8080/health delay=60s timeout=5s period=10s #success=1 #failure=5</span><br>     Readiness:    http-get http:<span class="hljs-comment">//:8181/ready delay=0s timeout=1s period=10s #success=1 #failure=3</span><br>     Environment:  &lt;none&gt;<br>     Mounts:<br>       /etc/coredns from config-volume (ro)<br>       /<span class="hljs-keyword">var</span>/<span class="hljs-keyword">run</span>/secrets/kubernetes.io/serviceaccount from kube-api-access-qdx6w (ro)<br> Conditions:<br>   <span class="hljs-keyword">Type</span>              Status<br>   Initialized       True<br>   Ready             False<br>   ContainersReady   False<br>   PodScheduled      True<br> Volumes:<br>   config-volume:<br>     <span class="hljs-keyword">Type</span>:      ConfigMap (a volume populated <span class="hljs-keyword">by</span> a ConfigMap)<br>     Name:      coredns<br>     Optional:  false<br>   kube-api-access-qdx6w:<br>     <span class="hljs-keyword">Type</span>:                    Projected (a volume that contains injected data from multiple sources)<br>     TokenExpirationSeconds:  3607<br>     ConfigMapName:           kube-root-<span class="hljs-keyword">ca</span>.crt<br>     ConfigMapOptional:       &lt;nil&gt;<br>     DownwardAPI:             true<br> QoS <span class="hljs-keyword">Class</span>:                   Burstable<br> Node-Selectors:              kubernetes.io/os=linux<br> Tolerations:                 CriticalAddonsOnly op=Exists<br>                              node-role.kubernetes.io/control-plane:NoSchedule<br>                              node-role.kubernetes.io/master:NoSchedule<br>                              node.kubernetes.io/not-ready:NoExecute op=Exists <span class="hljs-keyword">for</span> 300s<br>                              node.kubernetes.io/unreachable:NoExecute op=Exists <span class="hljs-keyword">for</span> 300s<br> Events:<br>   <span class="hljs-keyword">Type</span>     Reason                  Age                  From               Message<br>   ----     ------                  ----                 ----               -------<br>   Warning  FailedScheduling        6m12s                default-scheduler  0/1 nodes are available: 1 node(s) had taint &#123;node.kubernetes.io/not-ready: &#125;, that the pod didn&#x27;t tolerate.<br>   Normal   Scheduled               6m7s                 default-scheduler  Successfully assigned kube-system/coredns-7d89d9b6b8-cch8p to chyiyaqing-poweredge-r720<br>   Warning  FailedCreatePodSandBox  6m6s                 kubelet            Failed to create pod sandbox: rpc <span class="hljs-keyword">error</span>: code = Unknown <span class="hljs-keyword">desc</span> = [failed to <span class="hljs-keyword">set</span> up sandbox container <span class="hljs-string">&quot;d165e9f1f627d4a9c1f0eac4492ae7d1db6a7a1fe2a92dd435380cac57b35011&quot;</span> network <span class="hljs-keyword">for</span> pod <span class="hljs-string">&quot;coredns-7d89d9b6b8-cch8p&quot;</span>: networkPlugin cni failed to <span class="hljs-keyword">set</span> up pod <span class="hljs-string">&quot;coredns-7d89d9b6b8-cch8p_kube-system&quot;</span> network: unable to allocate IP address: <span class="hljs-keyword">Post</span> <span class="hljs-string">&quot;http://127.0.0.1:6784/ip/d165e9f1f627d4a9c1f0eac4492ae7d1db6a7a1fe2a92dd435380cac57b35011&quot;</span>: dial tcp 127.0.0.1:6784: connect: connection refused, failed to clean up sandbox container <span class="hljs-string">&quot;d165e9f1f627d4a9c1f0eac4492ae7d1db6a7a1fe2a92dd435380cac57b35011&quot;</span> network <span class="hljs-keyword">for</span> pod <span class="hljs-string">&quot;coredns-7d89d9b6b8-cch8p&quot;</span>: networkPlugin cni failed to teardown pod <span class="hljs-string">&quot;coredns-7d89d9b6b8-cch8p_kube-system&quot;</span> network: Delete <span class="hljs-string">&quot;http://127.0.0.1:6784/ip/d165e9f1f627d4a9c1f0eac4492ae7d1db6a7a1fe2a92dd435380cac57b35011&quot;</span>: dial tcp 127.0.0.1:6784: connect: connection refused]<br>   Normal   SandboxChanged          63s (x25 over 6m5s)  kubelet            Pod sandbox changed, it will be killed and re-created.<br><br> # 通过Taint/Toleration 调整Master执行Pod的策略 (由于本地搭建环境kubeamd只有一个Master节点)<br> &gt; 默认情况下Master节点是不允许运行用户Pod的, Kubernetes依赖Taint/Toleration机制<br>   - 为节点打上污点(Taint)<br>     &gt; $ kubectl taint nodes &lt;node-1&gt; foo=bar:NoSchedule<br>   - 删除Taint<br>     ➜ kubectl taint nodes --all node-role.kubernetes.io/master-<br>     node/chyiyaqing-poweredge-r720 untainted<br> # 安装网络插件<br>     ➜ kubectl apply -f <span class="hljs-string">&quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &#x27;\n&#x27;)&quot;</span><br><br>     serviceaccount/weave-<span class="hljs-keyword">net</span> created<br>     clusterrole.rbac.authorization.k8s.io/weave-<span class="hljs-keyword">net</span> created<br>     clusterrolebinding.rbac.authorization.k8s.io/weave-<span class="hljs-keyword">net</span> created<br>     role.rbac.authorization.k8s.io/weave-<span class="hljs-keyword">net</span> created<br>     rolebinding.rbac.authorization.k8s.io/weave-<span class="hljs-keyword">net</span> created<br>     daemonset.apps/weave-<span class="hljs-keyword">net</span> created<br></code></pre></td></tr></table></figure>
<ul>
<li><p>kubernetes CNI (Container Network Interface)<br><img src="/misc/images/kubernetes-cni-architecture.png" srcset="/img/loading.gif" lazyload alt="CNI plugin architecture"></p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs applescript">&gt; Kubernetes supports CNI plugins <span class="hljs-keyword">for</span> <span class="hljs-keyword">the</span> communication <span class="hljs-keyword">between</span> pods.<br>&gt; kubeadm <span class="hljs-keyword">does</span> <span class="hljs-keyword">not</span> support kubenet. you should use a CNI plugin<br><br><span class="hljs-comment"># Kubernetes impose(施加) following rules for network communication:</span><br>  - All containers can communicate <span class="hljs-keyword">with</span> all other containers <span class="hljs-keyword">without</span> NAT<br>  - All nodes can communicate <span class="hljs-keyword">with</span> all container (<span class="hljs-keyword">and</span> vice-versa) <span class="hljs-keyword">without</span> NAT<br>  - The IP <span class="hljs-keyword">that</span> a container sees itself <span class="hljs-keyword">as</span> <span class="hljs-keyword">is</span> <span class="hljs-keyword">the</span> same IP <span class="hljs-keyword">that</span> others see <span class="hljs-keyword">it</span> <span class="hljs-keyword">as</span>.<br><br>CNI plugins generally use kube-proxy <span class="hljs-keyword">or</span> directory iptables <span class="hljs-keyword">for</span> routing. However, Cilium <span class="hljs-keyword">is</span> based <span class="hljs-keyword">on</span> BPF <span class="hljs-keyword">and</span> XDP <span class="hljs-keyword">to</span> provide a faster <span class="hljs-keyword">and</span> more scalable option.<br><br><span class="hljs-comment"># Plugins:</span><br>  - Flannel:<br>    - provides VXLAN tunneling solution 隧道解决方案<br>    - configuration <span class="hljs-keyword">and</span> management are very simple<br>    - <span class="hljs-keyword">does</span> <span class="hljs-keyword">not</span> support Network Policies<br>  - Calico:<br>    - default choice <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> most <span class="hljs-keyword">of</span> kubernetes platform (kubespary, docker enterprise)<br>    - uses BGP <span class="hljs-keyword">and</span> Bird, a daemon called Felix configures routes <span class="hljs-keyword">on</span> Bird<br>    - supports IP-IP encapsulation <span class="hljs-keyword">if</span> BGP cannot be used.<br>    - supports Network Policies<br>    - uses iptables <span class="hljs-keyword">for</span> routing <span class="hljs-keyword">but</span> <span class="hljs-keyword">it</span> can be configured <span class="hljs-keyword">to</span> use kube-proxy&#x27;s IPVS mode.<br>  - Weave:<br>    - Provides VXLAN tunneling solution<br>    - all <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> nodes are connected <span class="hljs-keyword">as</span> mesh which allows <span class="hljs-keyword">it</span> <span class="hljs-keyword">to</span> <span class="hljs-built_in">run</span> <span class="hljs-keyword">on</span> paritially connected networks.<br>    - stores configuration files <span class="hljs-keyword">on</span> pods <span class="hljs-keyword">instead of</span> kubernetes CRDs <span class="hljs-keyword">or</span> etcd<br>    - has an encryption library<br>    - supports Network Policies<br>  - Cilium<br>    - Linux kernel must be <span class="hljs-keyword">at</span> least <span class="hljs-number">4.9</span><br>  - kube-router:<br>    -<br></code></pre></td></tr></table></figure>
<ul>
<li>Terminology<ul>
<li>kube-proxy<ul>
<li>Kube-proxy tree mods: 三个模组<ul>
<li>userspace:<br><img src="/misc/images/kube-proxy-userspace-mode.png" srcset="/img/loading.gif" lazyload alt="kube-proxy Userspace mode"><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs applescript">&gt; It adds rules <span class="hljs-keyword">to</span> iptables so <span class="hljs-keyword">that</span> all communication redirects <span class="hljs-keyword">through</span> proxy server. It <span class="hljs-keyword">is</span> no longer used <span class="hljs-keyword">since</span> <span class="hljs-keyword">it</span> <span class="hljs-keyword">is</span> much slower compared <span class="hljs-keyword">to</span> <span class="hljs-keyword">the</span> other modes.<br></code></pre></td></tr></table></figure></li>
<li>Iptables:<br><img src="/misc/images/kube-proxy-iptables-mode.png" srcset="/img/loading.gif" lazyload alt="kube-proxy iptables mode"><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">&gt; This mode adds rules <span class="hljs-keyword">to</span> iptables so that iptables redirects straight <span class="hljs-keyword">to</span> pods <span class="hljs-keyword">without</span> <span class="hljs-keyword">using</span> a proxy <span class="hljs-keyword">server</span>. It <span class="hljs-keyword">is</span> the <span class="hljs-keyword">default</span> mode <span class="hljs-keyword">of</span> kube-proxy.<br></code></pre></td></tr></table></figure></li>
<li>IPVS:<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">IPVS (IP Virtual <span class="hljs-keyword">Server</span>) <span class="hljs-keyword">is</span> layer<span class="hljs-number">-4</span> <span class="hljs-keyword">load</span> balancer inside the Linux kernel. It <span class="hljs-keyword">is</span> built <span class="hljs-keyword">on</span> top <span class="hljs-keyword">of</span> netfilter <span class="hljs-keyword">like</span> iptables. It utilizes hash <span class="hljs-keyword">table</span> <span class="hljs-keyword">instead</span> <span class="hljs-keyword">of</span> chain <span class="hljs-keyword">as</span> <span class="hljs-keyword">in</span> iptables.<br></code></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li>Network policy<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs applescript">Kubernetes specification <span class="hljs-keyword">that</span> can be used <span class="hljs-keyword">to</span> control traffic <span class="hljs-keyword">between</span> pods.<br></code></pre></td></tr></table></figure></li>
<li>Overlay Networks<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">An overlay network abstracts <span class="hljs-keyword">a</span> physical (underlay) network <span class="hljs-built_in">to</span> <span class="hljs-built_in">create</span> virtual network. It provides simpler interface <span class="hljs-keyword">by</span> hiding complexities <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> underlay.<br></code></pre></td></tr></table></figure></li>
<li>VXLAN<br><img src="/misc/images/vxlan-architecture.png" srcset="/img/loading.gif" lazyload alt="VXLAN architecture"><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs applescript">VXLAN <span class="hljs-keyword">is</span> a network tunneling(隧道) protocol <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> Linux Kernel. Network tunneling means hiding protocol (VXLAN) within another protocol (TCP/IP).VXLAN tuneels layer <span class="hljs-number">2</span> frames inside <span class="hljs-keyword">of</span> Layer <span class="hljs-number">4</span> UDP datagrams.<br><br><span class="hljs-comment"># Linux network structure in VXLAN:</span><br>  - veth: Virtual ethernet pair, <span class="hljs-keyword">it</span> connects network namespaces<br>  - bridge: It <span class="hljs-keyword">is</span> used <span class="hljs-keyword">to</span> connect ethernet pairs <span class="hljs-keyword">in</span> Linux<br>  - vtep: VXLAN tunnel endpoint, <span class="hljs-keyword">it</span>&#x27;s entry/<span class="hljs-keyword">exit</span> point <span class="hljs-keyword">for</span> VXLAN tunnels<br></code></pre></td></tr></table></figure></li>
<li>BGP(Border gateway protocol) - 边界网关协议</li>
<li>BPF(Berkeley Packet Filter) - 伯克利数据包过滤器</li>
<li>XDP (eXpress Data Path)<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">XDP <span class="hljs-keyword">is</span> a data <span class="hljs-type">path</span> recently added <span class="hljs-keyword">to</span> Linux kernel. It relies <span class="hljs-keyword">on</span> eBPF <span class="hljs-keyword">to</span> <span class="hljs-keyword">perform</span> fast packet processing.<br></code></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>kubernetes安装Metrics Server</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; Metrics Server是集群中资源使用情况的聚合器, Metrics Server从kubelets收集资源指标，并通过Metrics API将他们暴露在Kubernetes apiserver中,以供Horizontal Pod Autoscaler和Vertical Pod Autoscaler使用.<br>&gt; Metrics Server不适用与非自动缩放目的，不要使用他将指标转发到监控解决方案，或作为监控解决方案指标的来源,这种情况可以使用kuberlet<span class="hljs-regexp">/metrics/</span>resource 端点收集指标<br><br><span class="hljs-comment"># Installation</span><br>- kubectl apply -f https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/kubernetes-sigs/m</span>etrics-server<span class="hljs-regexp">/releases/</span>latest<span class="hljs-regexp">/download/</span>components.yaml<br><br><span class="hljs-comment"># Fix: (cannot validate certificate, doesn&#x27;t contain any IP SANs)</span><br>  - $ kubectl edit deployment metrics-server -n kube-system<br>    &gt; modifying the metrics-server deployment template, and adding the argument - --kubelet-insecure-tls to the container args<br></code></pre></td></tr></table></figure></li>
<li><p>Kubernetes集群安装Dashboard</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># Dashboard(Web界面) 可视化插件</span><br>  ➜ wget kubectl apply -f https:<span class="hljs-regexp">//</span>raw.githubusercontent.com<span class="hljs-regexp">/kubernetes/</span>dashboard<span class="hljs-regexp">/v2.2.0/</span>aio<span class="hljs-regexp">/deploy/</span>recommended.yaml<br>  namespace/kubernetes-dashboard created<br>  serviceaccount/kubernetes-dashboard created<br>  service/kubernetes-dashboard created<br>  secret/kubernetes-dashboard-certs created<br>  secret/kubernetes-dashboard-csrf created<br>  secret/kubernetes-dashboard-key-holder created<br>  configmap/kubernetes-dashboard-settings created<br>  role.rbac.authorization.k8s.io/kubernetes-dashboard created<br>  clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created<br>  rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created<br>  clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created<br>  deployment.apps/kubernetes-dashboard created<br>  service/dashboard-metrics-scraper created<br>  Warning: spec.template.metadata.annotations[seccomp.security.alpha.kubernetes.io/pod]: deprecated since v1.<span class="hljs-number">19</span>; use the <span class="hljs-string">&quot;seccompProfile&quot;</span> field instead<br>  deployment.apps/dashboard-metrics-scraper created<br><br><span class="hljs-comment"># 查看Dashboard对应的Pod状态</span><br>➜ kubectl get pods -n kubernetes-dashboard<br>NAME                                         READY   STATUS    RESTARTS   AGE<br>dashboard-metrics-scraper-<span class="hljs-number">856586</span>f554-w4vvw   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">5</span>m19s<br>kubernetes-dashboard-<span class="hljs-number">78</span>c79f97b4-l8nmb        <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">5</span>m19s<br><br><span class="hljs-comment"># 命令行代理 kubectl 访问DashBoard</span><br>$ kubectl proxy --address=<span class="hljs-string">&#x27;0.0.0.0&#x27;</span> --port=<span class="hljs-number">8001</span> --accept-hosts=<span class="hljs-string">&#x27;.*&#x27;</span><br><br><span class="hljs-comment"># 从集群外部访问Dashboard 需要使用Ingress</span><br></code></pre></td></tr></table></figure></li>
<li><p>Kubernetes部署存储插件</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">&gt; 容器持久化存储,用来保存容器存储状态,存储插件会在容器中挂在一个基于网络或者其他机制的远程数据卷. 使得在容器里创建的文件，实际上保存在远程存储服务器上,<br><br># Kubernetes 存储插件 - Rook<br>  &gt; Rook项目是一个基于Ceph的Kubernetes存储插件，不同于Ceph的简单封装，Rook加入了对平扩展、迁移、灾难备份、监控等大量的企业级功能.<br>  - 部署基于Rook持久化存储集群以容器方式运行<br>    $ git clone <span class="hljs-comment">--single-branch --branch release-1.7 https://github.com/rook/rook.git</span><br>    cd rook/<span class="hljs-keyword">cluster</span>/examples/kubernetes/ceph<br>    kubectl <span class="hljs-keyword">create</span> -f crds.yaml -f common.yaml -f <span class="hljs-keyword">operator</span>.yaml<br>    kubectl <span class="hljs-keyword">create</span> -f <span class="hljs-keyword">cluster</span>.yaml<br><br>  - 查看Rook部署的Namespace<br>    ➜ k <span class="hljs-keyword">get</span> pods -n rook-ceph<br>    <span class="hljs-type">NAME</span>                                           READY   STATUS    RESTARTS   AGE<br>    csi-cephfsplugin<span class="hljs-number">-7</span>l9xb                         <span class="hljs-number">3</span>/<span class="hljs-number">3</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">15</span>m<br>    csi-cephfsplugin-provisioner<span class="hljs-number">-689686</span>b44-qpt5q   <span class="hljs-number">6</span>/<span class="hljs-number">6</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">15</span>m<br>    csi-rbdplugin-provisioner<span class="hljs-number">-5775</span>fb866b<span class="hljs-number">-25224</span>     <span class="hljs-number">6</span>/<span class="hljs-number">6</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">15</span>m<br>    csi-rbdplugin-vvq94                            <span class="hljs-number">3</span>/<span class="hljs-number">3</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">15</span>m<br>    rook-ceph-<span class="hljs-keyword">operator</span><span class="hljs-number">-7</span>bdb744878-zz2fm            <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">24</span>m<br><br>  &gt; Kubernetes项目创建的所有Pod就能够通过Persistent Volume (PV) 和 Persistent Volume Claim (PVC) 的方式，在容器里挂载由Ceph提供的数据卷<br><br>  - <span class="hljs-keyword">Storage</span><br>    - Block: <span class="hljs-keyword">Create</span> block <span class="hljs-keyword">storage</span> <span class="hljs-keyword">to</span> be consumed <span class="hljs-keyword">by</span> a pod (RWO)<br>      &gt; <span class="hljs-keyword">Before</span> Rook can provision <span class="hljs-keyword">storage</span>, a **StorageClass** <span class="hljs-keyword">and</span> **CephBlockPool** need <span class="hljs-keyword">to</span> be created.<br>    - Shared FileSystem: <span class="hljs-keyword">Create</span> a filesystem <span class="hljs-keyword">to</span> be shared across multiple pods (RWX)<br>    - <span class="hljs-keyword">Object</span>: <span class="hljs-keyword">Create</span> an <span class="hljs-keyword">object</span> store that <span class="hljs-keyword">is</span> accessible inside <span class="hljs-keyword">or</span> outside the Kubernetes <span class="hljs-keyword">cluster</span><br></code></pre></td></tr></table></figure></li>
<li><p>HELM</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-quote">&gt; Helm is the package manager for Kubernetes</span><br><br><span class="hljs-section"># Helm 三大概念</span><br><span class="hljs-bullet">  -</span> Chart: helm包<br><span class="hljs-code">    &gt; 包含Kubernetes集群内部运行应用程序,工具或服务所需的所有资源定义</span><br><span class="hljs-code">  - Repository: 仓库</span><br><span class="hljs-code">    &gt; 存放和共享charts</span><br><span class="hljs-code">  - Release:</span><br><span class="hljs-code">    &gt; 运行在Kubernetes集群中的chart实例</span><br><span class="hljs-code"></span><br><span class="hljs-section"># helm search - 查找Charts</span><br></code></pre></td></tr></table></figure></li>
</ul>
<h2 id="Kubernetes-IN-Docker-Kind"><a href="#Kubernetes-IN-Docker-Kind" class="headerlink" title="Kubernetes IN Docker (Kind)"></a>Kubernetes IN Docker (Kind)</h2><blockquote>
<p>local clusters for testing Kubernetes</p>
</blockquote>
<figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs n1ql"># Installation<br>  $ go install sigs.k8s.io/kind@v0.11.1<br><br># Creating a Cluster<br>  $ kind <span class="hljs-keyword">create</span> <span class="hljs-keyword">cluster</span> # Default <span class="hljs-keyword">cluster</span> context name <span class="hljs-keyword">is</span> <span class="hljs-symbol">`kind`</span><br>  Creating <span class="hljs-keyword">cluster</span> <span class="hljs-string">&quot;kind&quot;</span> ...<br>   ✓ Ensuring node image (kindest/node:v1<span class="hljs-number">.21</span><span class="hljs-number">.1</span>) 🖼<br>   ✓ Preparing nodes 📦<br>   ✓ Writing configuration 📜<br>   ✓ Starting control-plane 🕹️<br>   ✓ Installing CNI 🔌<br>   ✓ Installing StorageClass 💾<br>  <span class="hljs-keyword">Set</span> kubectl context <span class="hljs-keyword">to</span> <span class="hljs-string">&quot;kind-kind&quot;</span><br>  You can now <span class="hljs-keyword">use</span> your <span class="hljs-keyword">cluster</span> <span class="hljs-keyword">with</span>:<br><br>  kubectl <span class="hljs-keyword">cluster</span>-info --context kind-kind<br><br>  <span class="hljs-keyword">Not</span> sure what <span class="hljs-keyword">to</span> <span class="hljs-keyword">do</span> next? 😅  Check out https://kind.sigs.k8s.io/docs/<span class="hljs-keyword">user</span>/quick-<span class="hljs-keyword">start</span>/<br><br>  ❯ kubectl <span class="hljs-keyword">cluster</span>-info --context kind-kind  # interact <span class="hljs-keyword">with</span> a specific <span class="hljs-keyword">cluster</span><br>  Kubernetes control plane <span class="hljs-keyword">is</span> running at https://<span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">45967</span><br>  CoreDNS <span class="hljs-keyword">is</span> running at https://<span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">45967</span>/api/v1/namespaces/kube-<span class="hljs-keyword">system</span>/services/kube-dns:dns/proxy<br><br>  <span class="hljs-keyword">To</span> further debug <span class="hljs-keyword">and</span> diagnose <span class="hljs-keyword">cluster</span> problems, <span class="hljs-keyword">use</span> <span class="hljs-string">&#x27;kubectl cluster-info dump&#x27;</span>.<br><br>  ❯ kind get clusters  # list kind clusters<br>  kind<br></code></pre></td></tr></table></figure>

<h2 id="容器化应用"><a href="#容器化应用" class="headerlink" title="容器化应用"></a>容器化应用</h2><ul>
<li>Kubernetes API 对象定义<figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs gauss">&gt; Kubernetes 不推荐使用命令行方式直接运行容器(kubectl <span class="hljs-keyword">run</span>), 而是希望使用YAML方式(kubectl <span class="hljs-keyword">create</span> -f yaml)<br>&gt; 使用一个API对象(Deployment)管理另一种API对象(Pod)的方式叫做“控制器”模式 (Controller pattern)<br>&gt; Pod 是Kubernetes世界里的“应用”,而一个应用可以由多个容器组成.<br><br>- metadata: API对象的元数据<br>- spec: 描述它要表达的功能<br>- labels: 一组<span class="hljs-built_in">key</span>-value格式的标签<br>- spec.selector.matchLabels: Label Selector 标签选择器<br>- annotations: 一组<span class="hljs-built_in">key</span>-value格式的内部信息(kubernetes组件本身感兴趣, 在Kubernetes运行过程中被自动加载到API对象上)<br><br>➜ k get pods -l app=nginx<br>NAME                                READY   STATUS    RESTARTS   AGE<br>nginx-deployment<span class="hljs-number">-5</span>d59d67564<span class="hljs-number">-8</span>qtq5   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">11</span>m<br>nginx-deployment<span class="hljs-number">-5</span>d59d67564-xx29g   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">11</span>m<br><br><span class="hljs-meta"># 使用kubectl apply 统一进行kubernetes对象的创建和更新操作</span><br>$ k apply -f nginx-deployment.yaml<br>$ k <span class="hljs-built_in">exec</span> -it nginx-deployment<span class="hljs-number">-748</span>c6fff66-plhwq -- /bin/bash<br>$ k <span class="hljs-keyword">delete</span> -f nginx-deployment.yaml<br><br><span class="hljs-meta"># emptyDir</span><br>  &gt; 不显式声明宿主主机目录的<span class="hljs-built_in">Volume</span>,Kubernetes会在宿主主机上创建一个临时目录,这个目录会被绑定到容器所声明的<span class="hljs-built_in">Volume</span>目录上(Kubernetes的emptyDir类型，只是把kubernetes创建的临时目录作为<span class="hljs-built_in">Volume</span>宿主机目录，交给Docker)<br><br><span class="hljs-meta"># hostPath</span><br>  &gt; 显式的<span class="hljs-built_in">Volume</span>定义<br>  ...<br>    volumes:<br>      - name: nginx-vol<br>        hostPath:<br>          path: <span class="hljs-string">&quot; /var/data&quot;</span><br></code></pre></td></tr></table></figure></li>
<li>Pod实现原理<figure class="highlight node-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs node-repl"><span class="hljs-meta">&gt;</span> <span class="javascript">Pod是Kuberntes项目的原子调度单位,kubernetes项目的调度器是统一按照Pod而非容器的资源需求进行计算</span><br><span class="hljs-meta">&gt;</span> <span class="javascript">Docker容器的本质<span class="hljs-string">&quot;Namespace隔离，Cgroups限制，rootfs文件系统&quot;</span></span><br><span class="hljs-meta">&gt;</span> <span class="javascript">Pod是Kubernetes里院子调度单位，Kubernetes项目的调度器是统一按照Pod而非容器的资源需求进行计算.</span><br><br># 展示系统中正在运行的进程树状结构<br>$ pstree - display a tree of process<br><br><span class="hljs-meta">&gt;</span> <span class="javascript">容器的<span class="hljs-string">&quot;单进程模型&quot;</span>并不是指容器里只能运行<span class="hljs-string">&quot;一个&quot;</span>进程,而是指容器没有管理多个进程的能力,</span><br><span class="hljs-meta">&gt;</span> <span class="javascript">Pod在Kubernetes项目里“容器设计模型”</span><br><span class="hljs-meta">&gt;</span> <span class="javascript">Pod其实是一组共享了某些资源的容器;Pod里的所有容器共享的是一个Network Namespace,并且可以声明共享一个Volume.</span><br><span class="hljs-meta">&gt;</span> <span class="javascript">Pod实际上扮演传统基础设施里<span class="hljs-string">&quot;虚拟机&quot;</span>的角色，而容器则是这个虚拟机里运行的用户程序</span><br></code></pre></td></tr></table></figure>
<ul>
<li>Pod Infra容器<br><img src="/misc/images/kubernetes-pod-infra.png" srcset="/img/loading.gif" lazyload alt="Pod Infra"><figure class="highlight node-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs node-repl"><span class="hljs-meta">&gt;</span> <span class="javascript">Kubernetes项目中Pod实现使用一个中间容器，这个容器叫做Infra容器,在Pod中,Infra容器都是第一个被创建的容器</span><br><span class="hljs-meta">&gt;</span> <span class="javascript">Infra 容器使用k8s.gcr.io/pause镜像使用汇编语言编写，永远处于<span class="hljs-string">&quot;暂停&quot;</span>状态的容器,解压后大小只有<span class="hljs-number">100</span>～200KB</span><br><span class="hljs-meta">&gt;</span> <span class="javascript">Pod声明周期只跟Infra容器一致，而与容器A和B无关</span><br></code></pre></td></tr></table></figure></li>
<li>容器设计模式<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> sidecar</span><br><span class="hljs-meta">  &gt;</span><span class="bash"> 我们可以在一个Pod中启动一个辅助容器，来完成一些独立主容器之外的工作</span><br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash"> Istio - 微服务治理项目</span><br><span class="hljs-meta">  &gt;</span><span class="bash"> 使用sidecar容器完成微服务治理的原理</span><br></code></pre></td></tr></table></figure></li>
</ul>
</li>
<li>深入解析Pod对象(-): 基本概念<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-quote">&gt; Kubernetes 项目的最小编排单元 &quot;Pod&quot;</span><br><span class="hljs-quote">&gt; Pod扮演的是传统部署环境里&quot;虚拟机&quot;的角色</span><br><br><span class="hljs-section"># Pod属性</span><br><span class="hljs-bullet">  -</span> 调度、网络、存储、安全<br><span class="hljs-bullet">  -</span> NodeSelector (将Pod与Node进行绑定的字段)<br><span class="hljs-bullet">  -</span> NodeName: (调度的结果)<br><span class="hljs-bullet">  -</span> 凡是Pod中的容器要共享宿主机的Namespace,一定是Pod级别的定义<br><br><span class="hljs-section"># Container属性</span><br><span class="hljs-bullet">  -</span> ImagePullPolicy: 镜像拉取策略<br><br><span class="hljs-section"># Pod对象在Kubernetes中的声明周期</span><br><span class="hljs-bullet">  -</span> phase:<br><span class="hljs-bullet">    -</span> Pending: Pod的YAML文件已经提交Kubernetes, API对象已经被创建保存在Etcd当中<br><span class="hljs-bullet">    -</span> Running: Pod已经调度成功,与具体节点绑定<br><span class="hljs-bullet">    -</span> Succeeded: Pod中所有容器都正常运行完毕，并且已经退出<br><span class="hljs-bullet">    -</span> Failed: Pod中至少有一个容器以不正常的状态退出<br><span class="hljs-bullet">    -</span> Unknown: Pod状态不能持续被kubelet上报给kube-apiserver<br><span class="hljs-bullet">  -</span> status.condation<br><span class="hljs-bullet">    -</span> PodScheduled:<br><span class="hljs-bullet">    -</span> Initialized<br><span class="hljs-bullet">    -</span> Ready<br><span class="hljs-bullet">    -</span> ContainersReady<br><span class="hljs-section"># Volume</span><br><span class="hljs-bullet">  -</span> Projected Volume<br><span class="hljs-bullet">    -</span> Secret: 加密数据存放在Etcd,通过Pod容器挂载Volume方式访问Secret,Secret对象存储数据经过base64转码<br><span class="hljs-bullet">    -</span> ConfigMap: 保存不需要加密、应用所需的配置信息<br><span class="hljs-bullet">    -</span> Downward API: 直接获取Pod API 对象本身的信息<br><span class="hljs-bullet">      -</span> spec.nodeName: 宿主机名字<br><span class="hljs-bullet">      -</span> status.hostIP: 宿主机IP<br><span class="hljs-bullet">      -</span> metadata.name: Pod名字<br><span class="hljs-bullet">      -</span> metadata.namespace: Pod的Namespace<br><span class="hljs-bullet">      -</span> status.podIP: Pod的IP<br><span class="hljs-bullet">      -</span> spec.serviceAccountName:<br><span class="hljs-bullet">      -</span> metadata.uid<br><span class="hljs-bullet">      -</span> metadata.labels<br><span class="hljs-bullet">      -</span> metadata.annotations<br><span class="hljs-bullet">      -</span> metadata.labels<br><span class="hljs-bullet">      -</span> metadata.annotations<br><span class="hljs-bullet">    -</span> ServiceAccountToken<br><span class="hljs-code">      &gt; Service Account对象是Kubernetes系统内置的一种&quot;服务账户&quot;,是Kubernetes进行权限分配的对象</span><br><span class="hljs-code"></span><br>环境变量获取信息的方式不具备自动更新的能力,建议使用Volume文件的方式获取这些信息<br>这种把Kubernetes客户端以容器的方式运行在集群里，然后使用default Service Account自动授权的方式，称作&quot;InClusterConfig&quot;，Kubernetes API编程的授权方式<br><br><span class="hljs-section"># 容器健康检查和恢复机制</span><br><span class="hljs-bullet">  -</span> Probe(探针)<br><br>  &gt; Kubernetes中并没有Docker的Stop,虽然是Restart,<br></code></pre></td></tr></table></figure></li>
</ul>
<h2 id="Kubernetes-技能图谱"><a href="#Kubernetes-技能图谱" class="headerlink" title="Kubernetes 技能图谱"></a>Kubernetes 技能图谱</h2><p><img src="/misc/images/kubernetes-rollmap.jpg" srcset="/img/loading.gif" lazyload alt="Kubernetes 技能图谱"></p>
<h2 id="Awesome-Tools"><a href="#Awesome-Tools" class="headerlink" title="Awesome Tools"></a>Awesome Tools</h2><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ahmetb/kubectx">kubectx + kubens: Power tools for kubectl</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ktr0731/evans">evans Universal gRPC client</a></li>
</ul>
<h3 id="WarmUp"><a href="#WarmUp" class="headerlink" title="WarmUp"></a>WarmUp</h3><ul>
<li>一旦要追求项目的普适性，那就一定要从顶层开始做好设计</li>
</ul>
<h3 id="专业术语"><a href="#专业术语" class="headerlink" title="专业术语"></a>专业术语</h3><ul>
<li>PaaS (Platform as a Service): 平台即服务</li>
<li>BaaS (Backend as a Service): 后端即服务</li>
<li>GA (General Availability): 一般可用性</li>
</ul>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/concepts/overview/">Kubernetes文档</a></li>
<li><a target="_blank" rel="noopener" href="https://www.usenix.org/system/files/conference/hotcloud16/hotcloud16_burns.pdf">容器设计模式</a></li>
</ul>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Cloud-Native/">Cloud Native</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/09/21/Cyclic-redundancy-check-Intro/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Cyclic redundancy check Intro</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/09/19/Prometheus-Grafana-Intro/">
                        <span class="hidden-mobile">Prometheus+Grafana Intro</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
