<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Docker Tips &amp; Tricks</title>
    <url>/2021/09/01/docker/</url>
    <content><![CDATA[<h2 id="Docker-Info"><a href="#Docker-Info" class="headerlink" title="Docker  Info"></a>Docker  Info</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”</span><br><span class="line"></span><br><span class="line">Cgroups技术是用来制造约束的主要手段</span><br><span class="line">Namespace技术则是用来修改进程试图的主要方法</span><br></pre></td></tr></table></figure>
<span id="more"></span>

<h2 id="Docker-architecture"><a href="#Docker-architecture" class="headerlink" title="Docker architecture"></a>Docker architecture</h2><blockquote>
<p>Docker uses a client-server architecture.</p>
</blockquote>
<p><img src="/misc/images/architecture.svg" alt="docker architecture"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Docker 仓库操作</span><br><span class="line">  docker pull/push</span><br><span class="line"></span><br><span class="line"># Docker 镜像管理</span><br><span class="line">  docker images/rmi/build</span><br><span class="line"></span><br><span class="line"># Docker 生命周期管理</span><br><span class="line">  docker run/start/stop/rm</span><br><span class="line"></span><br><span class="line"># to delete all containers including its volumes use,</span><br><span class="line">$ docker rm -vf $(docker ps -a -q)</span><br><span class="line"></span><br><span class="line"># to delete all the images</span><br><span class="line">$ docker rmi -f $(docker images -a -q)</span><br></pre></td></tr></table></figure>

<h2 id="Docker-Tips"><a href="#Docker-Tips" class="headerlink" title="Docker Tips"></a>Docker Tips</h2><ul>
<li><p><strong>Docker Tip #1</strong>: Docker 容器进程</p>
<blockquote>
<p>A Docker container is just a process/service that runs directly on your machine. It is slightly different than a regular process because the Docker daemon along with the linux kernel do a few things(<strong>Cgroups</strong>、<strong>Namespace</strong>) to ensure it runs in total isolation<br>Docker容器是一种特殊的进程,和虚拟机差别很大</p>
</blockquote>
</li>
<li><p><strong>Docker Tip #2</strong>: COPY vs. ADD in a Dockerfile</p>
<blockquote>
<p>COPY 和 ADD 功能很相似，都可以从指定目录拷贝数据到Docker镜像中.</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># COPY 和 ADD 区别</span><br><span class="line">1. COPY: 只能从本机文件或目录中拷贝到镜像中</span><br><span class="line">2. ADD: 不仅可以从本机文件或目录中拷贝，还可以使用URL引入外部的文件地址拷贝到镜像中</span><br><span class="line">  $ ADD rootfs.tar.gz /</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #3</strong>: 追加 Docker Run 指令减少镜像大小</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Before Dockerfile -- 新增三个层lager</span><br><span class="line">RUN wget -O myfile.tar.gz http://example.com/myfile.tar.gz</span><br><span class="line">RUN tar -xvf myfile.tar.gz -C /usr/src/myapp</span><br><span class="line">RUN rm myfile.tar.gz</span><br><span class="line"></span><br><span class="line"># After Dockerfile -- 新增一个层layer</span><br><span class="line">RUN wget -O myfile.tar.gz http://example.com/myfile.tar.gz \</span><br><span class="line">  &amp;&amp; tar -xvf myfile.tar.gz -C /usr/src/myapp \</span><br><span class="line">  &amp;&amp; rm myfile.tar.gz</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #4</strong>: Docker Base镜像OS和Host OS没有关系</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Docker Image OS: 定义在Dockerfile文件的Base镜像的系统</span><br><span class="line">Host OS: 运行Docker image的环境</span><br><span class="line">You can use whatever base image you want for your Docker images.</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #5</strong>: 使用相同Base镜像的好处</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">You could use a different base OS for each Docker image, but then you lose out on the ability to cache it across all of your images</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #6</strong>: RUN vs. CMD in a Dockerfile</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RUN: 在镜像内执行命令，这些指令仅仅在构建build镜像中执行一次，并且将构建结果写入新larger层中.</span><br><span class="line">CMD: 在启动容器时定义默认的运行的指令, 这种动作发生运行时run-time</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #7</strong>: Base Docker Image Alpine</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Why Alpine?</span><br><span class="line">&gt; Small. Simple. Secure. Alpine Linux is a security-oriented, lightweight Linux distribution based on musl libc and busybox.</span><br><span class="line">&gt; Alpine is about 30x smaller than Debian.</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #8</strong>: Project Structure with Multiple Dockerfiles and Docker Compose</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ubuntu in ~/chyi/micro-services at 3BPlus on 🐳 v20.10.8</span><br><span class="line">➜ tree -L 2</span><br><span class="line">.</span><br><span class="line">├── auth</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">├── billing</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">├── contact</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">├── docker-compose.yml</span><br><span class="line">└── user</span><br><span class="line">    └── Dockerfile</span><br><span class="line"></span><br><span class="line">4 directories, 5 files</span><br><span class="line"></span><br><span class="line">The docker-compose.yaml</span><br><span class="line">ubuntu in ~/chyi/micro-services at 3BPlus on 🐳 v20.10.8</span><br><span class="line">➜ cat docker-compose.yml</span><br><span class="line">version: &#x27;3&#x27;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">    auth:</span><br><span class="line">        build: &#x27;./auth&#x27;</span><br><span class="line">    billing:</span><br><span class="line">        build: &#x27;./billing&#x27;</span><br><span class="line">    contact:</span><br><span class="line">        build: &#x27;./contact&#x27;</span><br><span class="line">    user:</span><br><span class="line">        build: &#x27;./user&#x27;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #9</strong>: 使用Volumes</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># docker-compose.yaml</span><br><span class="line">services:</span><br><span class="line">  app:</span><br><span class="line">    # Mount the crrent directoy into `/app` inside the running container.</span><br><span class="line">    volumes:</span><br><span class="line">      - &#x27;.:/app&#x27;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #10</strong>: Published Ports</p>
<blockquote>
<p>Creates a firwaall rule which maps a container port to a port on the Docker host to the outside world.</p>
</blockquote>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Flag value</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left">-p 8080:80</td>
<td align="left">Map TCP port 80 in the container to port 8080 on the Docker host.</td>
</tr>
<tr>
<td align="left">-p 192.168.1.100:8080:80</td>
<td align="left">Map TCP port 80 in the container to port 8080 on the Docker host for connections to host IP 192.168.1.100.</td>
</tr>
<tr>
<td align="left">-p 8080:80/udp</td>
<td align="left">Map UDP port 80 in the container to port 8080 on the Docker host.</td>
</tr>
<tr>
<td align="left">-p 8080:80/tcp -p 8080:80/udp</td>
<td align="left">Map TCP port 80 in the container to TCP port 8080 on the Docker host, and map UDP port 80 in the container to UDP port 8080 on the Docker host.</td>
</tr>
</tbody></table>
<ul>
<li><p><strong>Docker Tip #11</strong>: dockerignore file</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.dockerignore: ignore certain files and folders from your Docker images</span><br><span class="line">  .git</span><br><span class="line">  .dockerignore</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #12</strong>: Manage Docker without sudo on Linux</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Add a docker group and then add your user to it:</span><br><span class="line">$ sudo groupadd docker</span><br><span class="line">$ docker usermod -aG docker $USER</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #13</strong>: Measure Docker Container’s Resources</p>
<blockquote>
<p>How much resources containers are using</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker stats</span><br><span class="line">CONTAINER ID   NAME                                                                                         CPU %     MEM USAGE / LIMIT     MEM %     NET I/O     BLOCK I/O         PIDS</span><br><span class="line">298d90f942e1   k8s_POD_kafka-zookeeper-0_default_a243d677-101b-493b-a076-d94f46785f22_0                     0.00%     724KiB / 3.704GiB     0.02%     0B / 0B     0B / 0B           1</span><br><span class="line">1d92a13e4a6f   k8s_POD_kafka-0_default_f7374645-9904-436c-bc8d-43ed415833c1_0                               0.00%     872KiB / 3.704GiB     0.02%     0B / 0B     0B / 0B           1</span><br><span class="line">b638c1bbd855   k8s_POD_postgres-postgresql-0_infrastructure_d9067ee1-6874-4018-a008-09362ad9330d_16         0.00%     868KiB / 3.704GiB     0.02%     0B / 0B     0B / 0B           1</span><br><span class="line">0fdc76799b4e   k8s_kube-flannel_kube-flannel-ds-nk6tj_kube-system_0a186e7a-c0d7-4282-9f5d-65ee20d0e13a_12   0.07%     15.4MiB / 50MiB       30.80%    0B / 0B     33.1MB / 0B       11</span><br><span class="line">4c3705247efa   k8s_kube-proxy_kube-proxy-xwfvl_kube-system_f46216cb-d018-4d82-b510-9be5e01cefca_12          0.00%     23.36MiB / 3.704GiB   0.62%     0B / 0B     43.7MB / 12.3kB   8</span><br><span class="line">16d5db1e7447   k8s_POD_kube-proxy-xwfvl_kube-system_f46216cb-d018-4d82-b510-9be5e01cefca_13                 0.00%     1.996MiB / 3.704GiB   0.05%     0B / 0B     487kB / 0B        1</span><br><span class="line">496aacf5fddf   k8s_POD_kube-flannel-ds-nk6tj_kube-system_0a186e7a-c0d7-4282-9f5d-65ee20d0e13a_13            0.00%     768KiB / 3.704GiB     0.02%     0B / 0B     0B / 0B           1</span><br><span class="line">1e328afeb116   dapr_zipkin                                                                                  0.17%     250.2MiB / 3.704GiB   6.60%     18MB / 0B   60MB / 0B         55</span><br><span class="line">27872f88cae3   dapr_placement                                                                               0.11%     5.992MiB / 3.704GiB   0.16%     18MB / 0B   13.6MB / 0B       10</span><br><span class="line">27c1f6daa81c   dapr_redis                                                                                   0.35%     5.633MiB / 3.704GiB   0.15%     18MB / 0B   10.7MB / 0B       5</span><br><span class="line"></span><br><span class="line">$ docker stats --format &quot;table &#123;&#123;.Container&#125;&#125;\t&#123;&#123;.CPUPerc&#125;&#125;\t&#123;&#123;.MemUsage&#125;&#125;&quot;</span><br><span class="line">CONTAINER      CPU %     MEM USAGE / LIMIT</span><br><span class="line">298d90f942e1   0.00%     724KiB / 3.704GiB</span><br><span class="line">1d92a13e4a6f   0.00%     872KiB / 3.704GiB</span><br><span class="line">b638c1bbd855   0.00%     868KiB / 3.704GiB</span><br><span class="line">0fdc76799b4e   2.37%     15.42MiB / 50MiB</span><br><span class="line">4c3705247efa   0.00%     23.36MiB / 3.704GiB</span><br><span class="line">16d5db1e7447   0.00%     1.996MiB / 3.704GiB</span><br><span class="line">496aacf5fddf   0.00%     768KiB / 3.704GiB</span><br><span class="line">1e328afeb116   0.21%     250.2MiB / 3.704GiB</span><br><span class="line">27872f88cae3   0.12%     5.992MiB / 3.704GiB</span><br><span class="line">27c1f6daa81c   0.34%     5.633MiB / 3.704GiB</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #14</strong>: Docker Compose vs Docker Stack</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Docker Compose: is an official tool that helps you manage your Docker containers by letting you define everything through a docker-compose.yml file.</span><br><span class="line"></span><br><span class="line"># docker stack: is a command that&#x27;s embedded into the Docker CLI. Lets you manage a cluster of Docker containers through Docker Swarm.</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #15</strong>: Metadata Docker Images with Labels</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Dockerfile example of adding 2 labels with 1 LABEL instruction:</span><br><span class="line">LABEL &lt;key&gt;=&lt;value&gt;</span><br><span class="line">LABEL version=&quot;1.0&quot; maintainer=&quot;chyi &lt;nick.chyi@gmail.com&gt;&quot;</span><br><span class="line"></span><br><span class="line"># Docker build example to add dynamic labels to your Docker images:</span><br><span class="line">$ docker build . --label &quot;version=1.0&quot; --label &quot;maintaner=chyi &lt;nick.chyi@gmail.com&gt;&quot;</span><br><span class="line"></span><br><span class="line"># docker inspect images</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #16</strong>: Named Volumes vs Path Based Volumes</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Named volumes</span><br><span class="line">  postgres:/var/lib/postgresql/data</span><br><span class="line"></span><br><span class="line">  docker-compose automatically create the postgres volume, if not you could running __$ docker volume create postgres__.</span><br><span class="line">  On Linux, the volume will get saved to /var/lib/docker/volumes/postgres/_data</span><br><span class="line"></span><br><span class="line"># Path based volumes</span><br><span class="line">  ./postgres:/var/lib/postgresql/data</span><br><span class="line"></span><br><span class="line">  postgres/ directory would get created in the current directory on the Docker host.</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #17</strong>: The Volume or Mount Flag</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Setting up a volume the old way with docker run:</span><br><span class="line">$ docker container run … -v &quot;$(pwd)&quot;:/myapp</span><br><span class="line"></span><br><span class="line"># Setting up the same volumes using the mount flag with docker run:</span><br><span class="line">$ docker container run … --mount type=bind,source=&quot;$(pwd)&quot;,target=/myapp</span><br><span class="line"></span><br><span class="line"># Docker compose</span><br><span class="line">volumes:</span><br><span class="line">  - type: &quot;bind&quot;</span><br><span class="line">    source: &quot;.&quot;</span><br><span class="line">    target: &quot;/myapp&quot;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #18</strong>: Connect to a Service Running on Docker Host</p>
<blockquote>
<p>Implementation of connecting to Docker host over a custom network with a static IP address.</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create a custom bridge Docker network</span><br><span class="line">ubuntu in ~ at 3BPlus</span><br><span class="line">➜ docker network create -d bridge --subnet 192.168.0.0/24 --gateway 192.168.0.1 mynet</span><br><span class="line">0330b879fcc8fb23eeb092cb66fd86f1796e7f0abe37df4978903cf8fd07217b</span><br><span class="line"></span><br><span class="line">ubuntu in ~ at 3BPlus</span><br><span class="line">➜ ifconfig</span><br><span class="line">br-0330b879fcc8: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.0.1  netmask 255.255.255.0  broadcast 192.168.0.255</span><br><span class="line">        ether 02:42:16:0c:c0:51  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line"># Start the Alpine container and drop into a Shell prompt.</span><br><span class="line">ubuntu in ~ at 3BPlus</span><br><span class="line">➜ docker container run --rm -it alpine sh</span><br><span class="line"></span><br><span class="line"># Install the ping utility.</span><br><span class="line">/ # apk update &amp;&amp; apk add iputils</span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.14/main/aarch64/APKINDEX.tar.gz</span><br><span class="line">fetch https://dl-cdn.alpinelinux.org/alpine/v3.14/community/aarch64/APKINDEX.tar.gz</span><br><span class="line">v3.14.2-5-gd4163d4c6c [https://dl-cdn.alpinelinux.org/alpine/v3.14/main]</span><br><span class="line">v3.14.2-4-ga15b4dc067 [https://dl-cdn.alpinelinux.org/alpine/v3.14/community]</span><br><span class="line">OK: 14810 distinct packages available</span><br><span class="line">(1/2) Installing libcap (2.50-r0)</span><br><span class="line">(2/2) Installing iputils (20210202-r0)</span><br><span class="line">Executing busybox-1.33.1-r3.trigger</span><br><span class="line">OK: 6 MiB in 16 packages</span><br><span class="line"></span><br><span class="line"># Ping the custom IP address we set up.</span><br><span class="line">/ # ping 192.168.0.1</span><br><span class="line"></span><br><span class="line"># You should see this output (hit CTRL+C to stop it)</span><br><span class="line">PING 192.168.0.1 (192.168.0.1) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.0.1: icmp_seq=1 ttl=64 time=0.336 ms</span><br><span class="line">64 bytes from 192.168.0.1: icmp_seq=2 ttl=64 time=0.293 ms</span><br><span class="line">^C</span><br><span class="line">--- 192.168.0.1 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 1013ms</span><br><span class="line">rtt min/avg/max/mdev = 0.293/0.314/0.336/0.021 ms</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #19</strong>: Show Total Disk Space Used by Docker</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ubuntu in ~ at 3BPlus</span><br><span class="line">➜ docker system df</span><br><span class="line">TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE</span><br><span class="line">Images          3         2         203.9MB   198.5MB (97%)</span><br><span class="line">Containers      3         1         2.524MB   0B (0%)</span><br><span class="line">Local Volumes   1         0         0B        0B</span><br><span class="line">Build Cache     0         0         0B        0B</span><br><span class="line"></span><br><span class="line"># -v flag (verbose) - will show the unique image size for each image</span><br><span class="line">ubuntu in ~ at 3BPlus</span><br><span class="line">➜ docker system df -v</span><br><span class="line">Images space usage:</span><br><span class="line"></span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED       SIZE      SHARED SIZE   UNIQUE SIZE   CONTAINERS</span><br><span class="line">alpine                latest    bb3de5531c18   4 days ago    5.337MB   0B            5.337MB       2</span><br><span class="line">hello-world           latest    bc11b176a293   7 weeks ago   9.136kB   0B            9.136kB       1</span><br><span class="line">bahamat/unix-1st-ed   latest    37aa142d2113   5 years ago   198.5MB   0B            198.5MB       0</span><br><span class="line"></span><br><span class="line">Containers space usage:</span><br><span class="line"></span><br><span class="line">CONTAINER ID   IMAGE         COMMAND            LOCAL VOLUMES   SIZE      CREATED       STATUS                   NAMES</span><br><span class="line">9023720cdee7   alpine        &quot;sh&quot;               0               2.52MB    5 hours ago   Up 5 hours               upbeat_kepler</span><br><span class="line">9e272ab58362   alpine        &quot;sh -c &#x27;exit 1&#x27;&quot;   0               0B        6 hours ago   Exited (1) 6 hours ago   naughty_blackburn</span><br><span class="line">d95cc7e19d43   hello-world   &quot;/hello&quot;           0               0B        7 weeks ago   Exited (0) 7 weeks ago   nifty_hellman</span><br><span class="line"></span><br><span class="line">Local Volumes space usage:</span><br><span class="line"></span><br><span class="line">VOLUME NAME   LINKS     SIZE</span><br><span class="line">user_my-db    0         0B</span><br><span class="line"></span><br><span class="line">Build cache usage: 0B</span><br><span class="line"></span><br><span class="line">CACHE ID   CACHE TYPE   SIZE      CREATED   LAST USED   USAGE     SHARED</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #20</strong>: Docker Compose Stop vs Down</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># docker-compose stop</span><br><span class="line">&gt; stop container, but it won&#x27;t remove them</span><br><span class="line"></span><br><span class="line"># docker-compose down</span><br><span class="line">&gt; stop container, removes the stopped containers as well as any networks that were created.</span><br><span class="line"></span><br><span class="line"># docker-compose down -v</span><br><span class="line">&gt; add remove all volumes too.</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Docker Tip #21</strong>: Difference between Docker Create, Start and Run</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create:</span><br><span class="line">  adds a writeable container on top of your image and sets it up for running whatever command you specified in you CMD. The container ID is reported back but it&#x27;s not started.</span><br><span class="line"></span><br><span class="line"># Start:</span><br><span class="line">  will start any stopped container.</span><br><span class="line"></span><br><span class="line"># Run:</span><br><span class="line">  combination of create and start, It creates the container and starts it.</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Have-a-Fun"><a href="#Have-a-Fun" class="headerlink" title="Have a Fun"></a>Have a Fun</h2><ul>
<li>Run the First Edition of Unix (1972) with Docker<blockquote>
<p>Run a PDP-11 simulator through Docker to interact with Unix as it was back in 1972</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker run --rm -it bahamat/unix-1st-ed</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Dockerfile</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo-next-gitalk</title>
    <url>/2021/09/01/hexo-next-gitalk/</url>
    <content><![CDATA[<h3 id="站点搭建过程"><a href="#站点搭建过程" class="headerlink" title="站点搭建过程"></a>站点搭建过程</h3><ul>
<li><a href="https://hexo.io/zh-cn/">hexo</a> : 快速、简洁且高校的博客框架</li>
<li><a href="https://github.com/next-theme/hexo-theme-next/blob/master/docs/zh-CN/README.md">next</a> : Hexo主题</li>
<li><a href="https://github.com/gitalk/gitalk">gitalk</a> : 依靠GitHub issue的评论系统</li>
</ul>
<span id="more"></span>

<h3 id="Settings-amp-Tips"><a href="#Settings-amp-Tips" class="headerlink" title="Settings &amp; Tips"></a>Settings &amp; Tips</h3><ul>
<li><p><strong>Show descripion</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改themes/next/_config.yml</span><br><span class="line">excerpt_description: true</span><br><span class="line"></span><br><span class="line"># 文章截断</span><br><span class="line">&lt;!--more--&gt;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>字数统计</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 安装插件 hexo-symbols-count-time</span><br><span class="line">$ npm install hexo-symbols-count-time</span><br><span class="line"></span><br><span class="line"># 修改hexo配置文件_config.yml</span><br><span class="line">  # Symbols count and time to read of articles for Hexo.</span><br><span class="line">  symbols_count_time:</span><br><span class="line">      symbols: true</span><br><span class="line">      time: true</span><br><span class="line">      total_symbols: true</span><br><span class="line">      total_time: true</span><br><span class="line"></span><br><span class="line"># 修改Next配置文件</span><br><span class="line">  # Post wordcount display settings</span><br><span class="line">  # Dependencies: https://github.com/next-theme/hexo-word-counter</span><br><span class="line">  symbols_count_time:</span><br><span class="line">    separated_meta: true</span><br><span class="line">    item_text_post: true</span><br><span class="line">    item_text_total: false</span><br><span class="line">    awl: 4</span><br><span class="line">    wpm: 275</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>micro-services</title>
    <url>/2021/09/01/micro-services/</url>
    <content><![CDATA[<p>介绍微服务架构设计</p>
<span id="more"></span>

<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  fmt.Println(<span class="string">&quot;Hello, world!&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机科学</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>DDD</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>echo-go-web-framework</title>
    <url>/2021/09/02/echo-go-web-framework/</url>
    <content><![CDATA[<h1 id="Echo"><a href="#Echo" class="headerlink" title="Echo"></a>Echo</h1><blockquote>
<p>高性能、可扩展、精简的Go Web框架</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">➜ go run main.go</span><br><span class="line"></span><br><span class="line">   ____    __</span><br><span class="line">  / __/___/ /  ___</span><br><span class="line"> / _// __/ _ \/ _ \</span><br><span class="line">/___/\__/_//_/\___/ v4.5.0</span><br><span class="line">High performance, minimalist Go web framework</span><br><span class="line">https://echo.labstack.com</span><br><span class="line">____________________________________O/_______</span><br><span class="line">                                    O\</span><br><span class="line">⇨ http server started on [::]:8080</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h2 id="功能概述"><a href="#功能概述" class="headerlink" title="功能概述"></a>功能概述</h2><ul>
<li>Optimized HTTP router which smartly prioritize routes</li>
<li>Build robust and scalable RESTful APIs</li>
<li>Group APIs</li>
<li>Extensible middleware framework</li>
<li>Define middleware at root, group or route level</li>
<li>Data binding for JSON, XML and form payload</li>
<li>Handy functions to send variety of HTTP response</li>
<li>Centralized HTTP error handling</li>
<li>Template rendering with any template engine</li>
<li>Define your format for the logger</li>
<li>Highly customizable</li>
<li>Automatic TLS via Let’s Encrypt</li>
<li>HTTP/2 support</li>
</ul>
]]></content>
      <tags>
        <tag>框架</tag>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>Distributed ID Generator</title>
    <url>/2021/09/02/Distributed-ID-Generator/</url>
    <content><![CDATA[<span id="more"></span>

<h1 id="Distributed-ID-Generator"><a href="#Distributed-ID-Generator" class="headerlink" title="Distributed ID Generator"></a>Distributed ID Generator</h1><ul>
<li>UUID<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">  &quot;testing&quot;</span><br><span class="line"></span><br><span class="line">  &quot;github.com/google/uuid&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func BenchmarkUUID(t *testing.B) &#123;</span><br><span class="line">  for i := 0; i &lt; t.N; i++ &#123;</span><br><span class="line">    _ = uuid.New()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">~/Downloads/uuid_demo via 🐹 v1.17 took 13s</span><br><span class="line">➜ go test -bench=.</span><br><span class="line">goos: darwin</span><br><span class="line">goarch: amd64</span><br><span class="line">pkg: uuid_demo</span><br><span class="line">cpu: Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz</span><br><span class="line">BenchmarkUUID-4   	 1390710	       844.7 ns/op</span><br><span class="line">PASS</span><br><span class="line">ok  	uuid_demo	2.351s</span><br><span class="line"></span><br><span class="line"># UUIDs are 128-bit hexadecimal numbers that are globally unique</span><br><span class="line"></span><br><span class="line"># 优点:</span><br><span class="line">  1. 生成足够简单，本地生成无网络消耗，具有唯一性</span><br><span class="line"># 缺点:</span><br><span class="line">  1. 无序的字符串，不具备趋势自增特性</span><br><span class="line">  2. 没有具体的业务含义</span><br><span class="line">  3. 长度过长16字节128位,36位长度的字符串,存储以及查询数据库性能消耗较大,数据库建议主键尽量越短越好，作为数据库主键UUID的无序性会导致数据位置频繁变动，严重影响性能</span><br></pre></td></tr></table></figure></li>
<li>基于数据库自增ID<blockquote>
<p>基于数据库的auto_increment自增ID完成可以充当分布式ID</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建数据表</span><br><span class="line">mysql&gt; CREATE TABLE SEQUENCE_ID (id bigint(20) unsigned NOT NULL auto_increment, value char(10) NOT NULL default &#x27;&#x27;, PRIMARY KEY (id)) ENGINE=MyISAM;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.08 sec)</span><br><span class="line"></span><br><span class="line"># MySQL使用存储过程插入数据</span><br><span class="line">delimiter $$</span><br><span class="line">create procedure bench_insert(count int unsigned)</span><br><span class="line">BEGIN</span><br><span class="line">  declare num int unsigned default 1;</span><br><span class="line">  declare c char(10) default repeat(&#x27;c&#x27;,10);</span><br><span class="line">  START TRANSACTION;</span><br><span class="line">  while num &lt;= count DO</span><br><span class="line">    insert into SEQUENCE_ID(`value`) values(c);</span><br><span class="line">    set num=num+1;</span><br><span class="line">  end while;</span><br><span class="line">COMMIT;</span><br><span class="line">END$$ delimiter ;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CALL bench_insert(10000);</span><br><span class="line"></span><br><span class="line">drop PROCEDURE bench_insert;</span><br><span class="line"></span><br><span class="line"># 当需要ID的时候，向表中插入记录返回主键ID.</span><br><span class="line"></span><br><span class="line"># 优点:</span><br><span class="line">  1. 实现简单、ID单调自增、数值类型查询速度快</span><br><span class="line"></span><br><span class="line">缺点:</span><br><span class="line">  1. DB单点存在宕机风险，无法扛住高并发场景</span><br></pre></td></tr></table></figure></li>
<li>基于数据库集群模式<blockquote>
<p>多数据库实例单独生产自增ID</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 设置启始值和自增布长</span><br><span class="line">  DB1:</span><br><span class="line">    set @@auto_increment_offset = 1; -- 起始值</span><br><span class="line">    set @@auto_increment_increment = 2; -- 步长</span><br><span class="line">  DB2:</span><br><span class="line">    set @@auto_increment_offset = 2; -- 起始值</span><br><span class="line">    set @@auto_increment_increment = 2; -- 步长</span><br><span class="line"></span><br><span class="line"># 优点:</span><br><span class="line">  解决DB单点问题</span><br><span class="line"></span><br><span class="line"># 缺点:</span><br><span class="line">  不利于后续扩容，而且实际上单个数据库自身压力还是很大，依旧无法满足高并发场景</span><br></pre></td></tr></table></figure></li>
<li>基于数据库的号段模式<blockquote>
<p>号段模式是分布式ID生成器主流实现方式之一，批量获取自增ID，每次从数据库取出一个号段范围，具体业务服务将本号段生成的自增ID加载内存</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  mysql&gt; CREATE TABLE id_generator (id int(10) NOT NULL, max_id bigint(20) NOT NULL COMMENT &#x27;当前最大id&#x27;, step int(20) NOT NULL COMMENT &#x27;号段的布长&#x27;, biz_type int(20) NOT NULL COMMENT &#x27;业务类型&#x27;, version int(20) NOT NULL COMMENT &#x27;版本号&#x27;, PRIMARY KEY(`id`));</span><br><span class="line">Query OK, 0 rows affected, 5 warnings (0.11 sec)</span><br><span class="line"></span><br><span class="line">  mysql&gt; describe id_generator;</span><br><span class="line">  +----------+--------+------+-----+---------+-------+</span><br><span class="line">  | Field    | Type   | Null | Key | Default | Extra |</span><br><span class="line">  +----------+--------+------+-----+---------+-------+</span><br><span class="line">  | id       | int    | NO   | PRI | NULL    |       |</span><br><span class="line">  | max_id   | bigint | NO   |     | NULL    |       |  -- 当前最大的可用id</span><br><span class="line">  | step     | int    | NO   |     | NULL    |       |  -- 代表号段的长度</span><br><span class="line">  | biz_type | int    | NO   |     | NULL    |       |  -- 不同业务类型</span><br><span class="line">  | version  | int    | NO   |     | NULL    |       |  -- 乐观锁，每次都更新version，保证并发时数据的正确性</span><br><span class="line">  +----------+--------+------+-----+---------+-------+</span><br><span class="line">  5 rows in set (0.04 sec)</span><br><span class="line"></span><br><span class="line">  update id_generator set max_id = #&#123;max_id+step&#125;, version = version + 1 where version = # &#123;version&#125; and biz_type = XXX</span><br></pre></td></tr></table></figure></li>
<li>基于Redis模式<blockquote>
<p>利用redis Incr 原子性自增</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  172.30.1.23:6002&gt; set seq_id 1</span><br><span class="line">  OK</span><br><span class="line">  172.30.1.23:6002&gt; incr seq_id</span><br><span class="line">  (integer) 2</span><br><span class="line">  172.30.1.23:6002&gt; get seq_id</span><br><span class="line">  &quot;2&quot;</span><br><span class="line">  172.30.1.23:6002&gt;</span><br><span class="line"></span><br><span class="line"># Benchmark</span><br><span class="line">ubuntu in ~ at 3BPlus took 4s</span><br><span class="line">➜ redis-benchmark -n 1000000 -t set,get,incr -P 16 -q -h 127.0.0.1 -p 6001 --cluster</span><br><span class="line">Cluster has 3 master nodes:</span><br><span class="line"></span><br><span class="line">Master 0: a733c21d3b735b9d026eb4d462ef6b367d8ebb98 172.30.1.23:6002</span><br><span class="line">Master 1: 9c35a4e211f6534861ed768dba592e85539b1377 172.30.1.23:6003</span><br><span class="line">Master 2: a901e497cb72819cf0765e9e4eb16c36399c437b 172.30.1.23:6001</span><br><span class="line"></span><br><span class="line">SET: 47001.32 requests per second, p50=15.199 msec</span><br><span class="line">GET: 101936.80 requests per second, p50=5.679 msec</span><br><span class="line">INCR: 46496.49 requests per second, p50=13.879 msec   -- 并发5万/s</span><br></pre></td></tr></table></figure></li>
<li>twitter snowflake<blockquote>
<p>雪花算法 (Snowflake) Twitter内部分布式采用的ID生成算法</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># The default Twitter format shown below.</span><br><span class="line">+--------------------------------------------------------------------------+</span><br><span class="line">| 1 Bit Unused | 41 Bit Timestamp |  10 Bit NodeID  |   12 Bit Sequence ID |</span><br><span class="line">+--------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">41 bits: store a timestamp with millisecond precision</span><br><span class="line">10 bits: store a node id - a range from 0 through 1023</span><br><span class="line">12 bits: store a sequence number - a range from 0 through 4095</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>ID Generator</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka Tips &amp; Tracks</title>
    <url>/2021/09/02/Kafka-Tips-Tracks/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>MySQL Tips &amp; Tracks</title>
    <url>/2021/09/02/MySQL-Tips-Tracks/</url>
    <content><![CDATA[<h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><h2 id="数据库日志"><a href="#数据库日志" class="headerlink" title="数据库日志"></a>数据库日志</h2><ul>
<li>重做日志 - redo log<blockquote>
<p>记录修改后的数据</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis Tips &amp; Tracks</title>
    <url>/2021/09/02/Redis-Tips-Tracks/</url>
    <content><![CDATA[<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><blockquote>
<p>Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache, and message broker.</p>
</blockquote>
<span id="more"></span>

<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><blockquote>
<p>Redis 持久化主要两大机制: AOF (Append Only File) 日志和RDB 快照</p>
</blockquote>
<ul>
<li><p>AOF - Append Only File</p>
<blockquote>
<p>AOF日志是Redis执行完命令，把数据写入内存，然后才记录日志,记录的是Redis收到的每一条命令</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 写后日志这种方式，先让系统执行命令，只有命令执行成功，才会被记录到日志中，避免出现记录错误命令的情况</span><br><span class="line"># AOF 是在命令执行后才记录日志，不会阻塞当前写操作</span><br><span class="line"></span><br><span class="line"># 写回磁盘策略 appendfsync</span><br><span class="line">  1. Always: 同步写回, 每个写命令执行完，立马同步将日志写回磁盘</span><br><span class="line">    &gt; 落盘操作属于慢速，回影响主线程性能</span><br><span class="line">  2. Everysec: 每秒写回,每个写命令执行完，先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘</span><br><span class="line">    &gt; 在避免影响主线程和避免数据丢失两者之间trade-off方式</span><br><span class="line">  3. No: 操作系统控制写回，每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘</span><br><span class="line">    &gt; 落盘时机交给操作系统，只要AOF记录没有写回磁盘，宕机对应的数据就丢失</span><br><span class="line"></span><br><span class="line"># 解决AOF文件过大的性能问题: AOF 重写</span><br><span class="line"></span><br><span class="line">  问题:</span><br><span class="line">    1. 文件系统本身对文件大小有限制，无法保存过大的文件</span><br><span class="line">    2. 文件过大，追加命令记录效率变低</span><br><span class="line">    3. 发生宕机，AOF记录命令要被重新执行，故障恢复比较缓慢，会影响Redis正常使用</span><br><span class="line"></span><br><span class="line">  AOF重写:</span><br><span class="line">    &gt; 重写机制可以将旧日志文件中的多条命令，在重写后的新日志中变成一条命令</span><br><span class="line">    &gt; AOF重写过程是由后台子进程bgrewriteaof完成，避免阻塞主线程，导致性能下降</span><br><span class="line">    &gt; 每次AOF重写时，Redis会执行一个内存拷贝，用于重写，然后使用两个日志保证重写过程中，新写入的数据不会丢失，而且，Redis采用额外的线程进行数据重写，过程不会阻塞主线程</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>RDB - 内存快照</p>
<blockquote>
<p>内存快照：指内存中的数据在某一个时刻的状态记录</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Redis两种命令生成RDB文件</span><br><span class="line">  1. save: 在主线程执行，会导致阻塞</span><br><span class="line">  2. bgsave: 创建子进程，专门用于写入RDB文件，避免主线程阻塞</span><br><span class="line">    &gt; bgsave子进程由主线程fork生成，共享主线程的所有内存数据，bgsave子进程运行后，开始读取主线程的内存数据，并把数据写入RDB文件</span><br><span class="line"></span><br><span class="line"># 增量快照:</span><br><span class="line">&gt; 做一次全量快照后，后续的快照支队修改的数据进行快照记录，可以避免每次全量快照的开销</span><br><span class="line"></span><br><span class="line"># 混合使用AOF日志和内存快照</span><br><span class="line">&gt; 内存快照以一定的频率执行，两次快照之间，使用AOF日志记录这期间的所有命令操作</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <tags>
        <tag>缓存</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Dev-Ops Tips &amp; Tracks</title>
    <url>/2021/09/03/Dev-Ops-Tips-Tracks/</url>
    <content><![CDATA[<h1 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. Programming</span><br><span class="line">2. Software Testing</span><br><span class="line">3. Operations</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title>Distribute Scraping for Gophers</title>
    <url>/2021/09/03/Distribute-Scraping-for-Gophers/</url>
    <content><![CDATA[<h1 id="分布式爬虫"><a href="#分布式爬虫" class="headerlink" title="分布式爬虫"></a>分布式爬虫</h1><blockquote>
<p>分布式爬虫是一套任务分发和执行系统，常见的任务分发，因为上下游存在速度不匹配问题，需要借助消息队列</p>
</blockquote>
<span id="more"></span>

<h2 id="分布式消息队列"><a href="#分布式消息队列" class="headerlink" title="分布式消息队列"></a>分布式消息队列</h2><ul>
<li>nats<blockquote>
<p>nats是Go实现的高性能分布式消息队列，适用于高并发吞吐量的消息分发场景.</p>
</blockquote>
</li>
</ul>
]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch Tips &amp; Tracks</title>
    <url>/2021/09/03/Elasticsearch-Tips-Tracks/</url>
    <content><![CDATA[<h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h1><blockquote>
<p>Elasticsearch是一个开源的分布式搜索与分析引擎，提供近实时搜索和聚合功能<br>Elastic Stack主要应用于：搜索、日志管理、安全分析、指标分析、业务分析、应用性能监控等多个领域<br>“Search is something that any application should have.”</p>
</blockquote>
<span id="more"></span>

<h2 id="Elastic-Stack-生态圈"><a href="#Elastic-Stack-生态圈" class="headerlink" title="Elastic Stack 生态圈"></a>Elastic Stack 生态圈</h2><ul>
<li><p>解决方案:</p>
<ul>
<li>搜索</li>
<li>日志分析</li>
<li>指标分析</li>
<li>安全分析</li>
</ul>
</li>
<li><p>可视化:</p>
<ul>
<li>Kibana: 可视化分析</li>
</ul>
</li>
<li><p>存储/计算:</p>
<ul>
<li>Elasticsearch: 核心引擎,提供数据存储、搜索和聚合的能力</li>
</ul>
</li>
<li><p>数据抓取:</p>
<ul>
<li>Logstash<blockquote>
<p>开源的服务器端数据处理管道，支持从不同来源采集数据，转换数据，并将数据发送到不同的存储库中</p>
</blockquote>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 特性:</span><br><span class="line">  1. 实时解析和转换数据</span><br><span class="line">    &gt; 从IP地址破译地理位置</span><br><span class="line">    &gt; 从PII数据匿名化，排除敏感字段</span><br><span class="line">  2. 可扩展</span><br><span class="line">  3. 可靠性安全性</span><br><span class="line">    &gt; Logstash 通过持久化队列保证至少将运行中的事件送达一次</span><br><span class="line">    &gt; 数据传输加密</span><br><span class="line">  4. 加密</span><br></pre></td></tr></table></figure>

<ul>
<li>Beats<blockquote>
<p>轻量级别数据采集器</p>
</blockquote>
</li>
</ul>
</li>
<li><p>X-Pack: 商业化套件</p>
</li>
</ul>
<blockquote>
<p>Elasticsearch与数据库的集成</p>
</blockquote>
<p><img src="/misc/images/Elastichsearch.png" alt="Elastichsearch"></p>
<blockquote>
<p>指标分析/日志分析</p>
</blockquote>
<ul>
<li>Data Collection(beats) -&gt; Buffering(redis,Kafkak) -&gt; Data Aggregation &amp; Processing(logstash) -&gt; Indexing &amp; storage(elasticsearch) -&gt; Analysis &amp; visualization(Kbana)</li>
</ul>
<h2 id="Elasticsearch-1"><a href="#Elasticsearch-1" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h2><ul>
<li><p>Elasticsearch 目录结构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ubuntu in ~/elasticsearch-7.14.1 at k8s-node1 took 45s</span><br><span class="line">➜ tree -L 1</span><br><span class="line">.</span><br><span class="line">├── bin                 -- 脚本文件，包括启动elasticsearch,安装插件，运行统计数据</span><br><span class="line">├── config              -- elasticsearch.yml 集群配置文件，user, role based 相关配置</span><br><span class="line">├── jdk                 -- Java 运行环境</span><br><span class="line">├── lib                 -- Java 类库</span><br><span class="line">├── LICENSE.txt</span><br><span class="line">├── logs                -- path.log 日志文件</span><br><span class="line">├── modules             -- 包含所有ES模块</span><br><span class="line">├── NOTICE.txt</span><br><span class="line">├── plugins             -- 包含所有已安装插件</span><br><span class="line">└── README.asciidoc</span><br></pre></td></tr></table></figure></li>
<li><p>JVM 配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改JVM - config/jvm.options</span><br><span class="line">  -Xms和Xms 最小最大内存设置成一样</span><br><span class="line">  -Xmx不超过机器内存的50%</span><br></pre></td></tr></table></figure></li>
<li><p>Run</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ bin/elasticsearch</span><br><span class="line">~ took 11m 31s</span><br><span class="line">➜ curl http://localhost:9200</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot; : &quot;a714f28827d5&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;docker-cluster&quot;,</span><br><span class="line">  &quot;cluster_uuid&quot; : &quot;96jmRuNUQxqFsGeWJjIo6g&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;7.14.1&quot;,</span><br><span class="line">    &quot;build_flavor&quot; : &quot;default&quot;,</span><br><span class="line">    &quot;build_type&quot; : &quot;docker&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;66b55ebfa59c92c15db3f69a335d500018b3331e&quot;,</span><br><span class="line">    &quot;build_date&quot; : &quot;2021-08-26T09:01:05.390870785Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;8.9.0&quot;,</span><br><span class="line">    &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,</span><br><span class="line">    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>Plugin 机制对系统扩展</p>
<blockquote>
<p>Discovery Plugin<br>Analysis Plugin<br>Security Plugin<br>Management Plugin<br>Ingest Plugin<br>Mapper Plugin<br>Backup Plugin</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ubuntu in ~ at k8s-node1 via 🐍 3.8.6</span><br><span class="line">➜ elasticsearch-plugin install analysis-icu  # 分词插件</span><br><span class="line">-&gt; Installing analysis-icu</span><br><span class="line">-&gt; Downloading analysis-icu from elastic</span><br><span class="line">[=================================================] 100%</span><br><span class="line">-&gt; Installed analysis-icu</span><br><span class="line">-&gt; Please restart Elasticsearch to activate any plugins installed</span><br><span class="line"></span><br><span class="line">ubuntu in ~ at k8s-node1 via 🐍 3.8.6 took 23s</span><br><span class="line">➜ elasticsearch-plugin list</span><br><span class="line">analysis-icu</span><br><span class="line"></span><br><span class="line">ubuntu in ~ at k8s-node1 via 🐍 3.8.6</span><br><span class="line">➜ curl http://localhost:9200/_cat/plugins</span><br><span class="line">k8s-node1 analysis-icu 7.14.1</span><br></pre></td></tr></table></figure></li>
<li><p>多集群<br><a href="/misc/code/elasticsearch/docker-compose.yml">docker-compose.yml</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">➜ curl -X GET &quot;localhost:9200/_cat/nodes?v=true&amp;pretty&quot;</span><br><span class="line">ip         heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name</span><br><span class="line">172.24.0.2           41          97  85    4.28    1.24     0.43 cdfhilmrstw -      es01</span><br><span class="line">172.24.0.3           56          97  85    4.28    1.24     0.43 cdfhilmrstw -      es03</span><br><span class="line">172.24.0.4           27          97  85    4.28    1.24     0.43 cdfhilmrstw *      es02</span><br></pre></td></tr></table></figure></li>
<li><p>Kibana:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ curl http://localhost:5601</span><br><span class="line"></span><br><span class="line"># Kibana Plugins 插件</span><br><span class="line">$ kibana-plugin install</span><br><span class="line">$ kibana-plugin list</span><br><span class="line">$ kibana remove</span><br></pre></td></tr></table></figure></li>
<li><p>Logstash:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Elasticsearch-基本概念"><a href="#Elasticsearch-基本概念" class="headerlink" title="Elasticsearch 基本概念"></a>Elasticsearch 基本概念</h2><ul>
<li><p>文档 Document</p>
<blockquote>
<p>Elasticsearch 是面向文档的，文档是所有可搜索数据的最小单位<br>文档会被序列化成JSON格式，保存在Elasticsearch中<br>每个文档都有一个Unique ID</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 文档元数据Metadata - 标注文档的相关信息</span><br><span class="line">  _index - 文档所属的索引名</span><br><span class="line">  _type  - 文档所属类型名</span><br><span class="line">  _id    - 文档唯一ID</span><br><span class="line">  _source - 文档原始JSON数据</span><br><span class="line">  _version - 文档的版本信息 -- 解决并发读写冲突</span><br><span class="line">  _score  - 相关性打分</span><br></pre></td></tr></table></figure></li>
<li><p>索引 Index</p>
<blockquote>
<p>将文档写入Elasticsearch的过程叫索引indexing</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mapping: 定义包含的文档的字段名和字段类型</span><br><span class="line">Setting: 定义不同数据分布</span><br><span class="line">Shard: 索引中的数据分散在Shards上</span><br></pre></td></tr></table></figure></li>
<li><p>节点 Node</p>
<blockquote>
<p>节点是Elasticsearch 实例</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-E node.name=node1</span><br><span class="line">每个节点启动后，会分配一个UID，保存在data目录下</span><br><span class="line"></span><br><span class="line"># Master-eligible nodes 和 Master Node</span><br><span class="line">  1. 节点启动默认是一个Master-eligible节点, -E node.master:false 禁止</span><br><span class="line">  2. Master-eligible节点可以参加选主流程，称为Master节点</span><br><span class="line">  3. 每个节点都保存集群状态，只有master节点才能修改集群状态</span><br><span class="line"></span><br><span class="line"># 集群状态 Cluster State</span><br><span class="line">  1. 所有节点信息</span><br><span class="line">  2. 所有的索引和相关Mapping 与 Setting信息</span><br><span class="line">  3. 分片的路由信息</span><br><span class="line"></span><br><span class="line"># Data Node &amp; Coordinating Node</span><br><span class="line">  1. Data Node: 可以保存数据的节点，保存分片数据</span><br><span class="line">  2. Coordinating Node: 负责接受Client请求，将请求分发到合适的节点，最终把结果汇集到一起</span><br><span class="line"></span><br><span class="line"># Hot &amp; Warm Node</span><br><span class="line"># Machine Learning Node</span><br><span class="line"># Tribe Node</span><br></pre></td></tr></table></figure></li>
<li><p>分片 Primary Shard &amp; Replica Shard</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#主分片: 解决数据水平扩展的问题</span><br><span class="line">  1. 一个分片是一个运行的Lucene的实例</span><br><span class="line">  2. 主分片在索引创建时指定，后续不允许修改,使用 Reindex修改</span><br><span class="line"></span><br><span class="line">#副本: 解决数据高可用的问题</span><br><span class="line">  1. 副本分片数，可以动态调整</span><br><span class="line">  2. 增加副本数，可以在一定程度上提高服务的可用性 (读取的吞吐)</span><br><span class="line"></span><br><span class="line">#分片设定-容量规划</span><br><span class="line">  1. 分片数设置过小:</span><br><span class="line">    a. 后续无法增加节点实现水平扩展</span><br><span class="line">    b. 单个分片的数据量过大，导致数据重新分配耗时</span><br><span class="line">  2. 分片设置过大:</span><br><span class="line">    a. 影响搜索结果的相关性打分，影响统计结果准确性</span><br><span class="line"></span><br><span class="line"># 查看集群状态</span><br><span class="line">  Green: 主分片和副片正常</span><br><span class="line">  Yellow: 主分片正常，副片不正常</span><br><span class="line">  Red: 主分片未能分配</span><br></pre></td></tr></table></figure></li>
<li><p>Elasticsearch vs 关系型数据库 抽象与类比</p>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">RDBMS</th>
<th align="left">Elasticsearch</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Table</td>
<td align="left">Index</td>
</tr>
<tr>
<td align="left">Row</td>
<td align="left">Document</td>
</tr>
<tr>
<td align="left">Column</td>
<td align="left">Field</td>
</tr>
<tr>
<td align="left">Schema</td>
<td align="left">Mapping</td>
</tr>
<tr>
<td align="left">SQL</td>
<td align="left">DSL</td>
</tr>
</tbody></table>
<ul>
<li><p>文档Document CRUD</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//create document. 自动生成_id</span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;</span><br><span class="line">  &quot;user&quot;: &quot;Mike&quot;,</span><br><span class="line">  &quot;message&quot;: &quot;trying out Kibana&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//create document. 指定Id, 如果ID已经存在，报错</span><br><span class="line">PUT users/_doc/1?op_type=create</span><br><span class="line">&#123;</span><br><span class="line">  &quot;user&quot;: &quot;Jack&quot;,</span><br><span class="line">  &quot;message&quot;: &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//create document. 指定Id, 如果ID已经存在，报错</span><br><span class="line">PUT users/_create/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;user&quot;: &quot;Jack&quot;,</span><br><span class="line">  &quot;message&quot;: &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Get the document by ID</span><br><span class="line">GET users/_doc/1</span><br><span class="line"></span><br><span class="line">// Index</span><br><span class="line">PUT users/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;user&quot;: &quot;Mike&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//Update 在原文档上增加字段</span><br><span class="line">POST users/_update/1/</span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;:&#123;</span><br><span class="line">    &quot;message&quot;: &quot;trying out Elasticsearch 3&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><ul>
<li>Bulk API<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 支持在一次API调用中，对不同的索引进行操作</span><br><span class="line">2. 支持四种类型操作:</span><br><span class="line">  Index</span><br><span class="line">  Create</span><br><span class="line">  Update</span><br><span class="line">  Delete</span><br><span class="line">3. 操作单条操作失败，不会影响其他操作</span><br><span class="line">4. 返回结果包括每一条操作的执行结果</span><br><span class="line"></span><br><span class="line">//Bulk操作</span><br><span class="line">POST _bulk</span><br><span class="line">&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;test&quot;, &quot;_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;field1&quot;: &quot;value1&quot;&#125;</span><br><span class="line">&#123;&quot;delete&quot;: &#123;&quot;_index&quot;: &quot;test&quot;, &quot;_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;create&quot;: &#123;&quot;_index&quot;: &quot;test2&quot;, &quot;_id&quot;: &quot;3&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;field1&quot;: &quot;value3&quot;&#125;</span><br><span class="line">&#123;&quot;update&quot;: &#123;&quot;_id&quot;:&quot;1&quot;, &quot;_index&quot;: &quot;test&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;doc&quot;: &#123;&quot;field2&quot;: &quot;value2&quot;&#125;&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>mget</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//mget -- 批量读取</span><br><span class="line">//可以减少网络连接，提高性能</span><br><span class="line">GET _mget</span><br><span class="line">&#123;</span><br><span class="line">  &quot;docs&quot;: [</span><br><span class="line">    &#123;&quot;_index&quot;: &quot;users&quot;, &quot;_id&quot;:1&#125;,</span><br><span class="line">    &#123;&quot;_index&quot;: &quot;comment&quot;, &quot;_id&quot;:1&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Elasticsearch-原理"><a href="#Elasticsearch-原理" class="headerlink" title="Elasticsearch 原理"></a>Elasticsearch 原理</h2><ul>
<li>图书和搜索引擎类比</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Type</th>
<th align="left">正排索引</th>
<th align="left">倒排索引</th>
</tr>
</thead>
<tbody><tr>
<td align="left">图书</td>
<td align="left">目录页</td>
<td align="left">索引页</td>
</tr>
<tr>
<td align="left">搜索引擎</td>
<td align="left">文档ID-&gt;文档内容和单词的关联</td>
<td align="left">单词到文档ID的关系</td>
</tr>
</tbody></table>
<ul>
<li><p>Elasticsearch 倒排索引</p>
<blockquote>
<p>Elasticsearch的JSON文档中每个字段，都有自己的倒排索引</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 单词词典(Term Dictionary)</span><br><span class="line">&gt; 记录所有文档的单词，记录单词到倒排列表的关联关系</span><br><span class="line">&gt; 通过B+树或哈希链表实现，满足高性能的插入与查询</span><br><span class="line"></span><br><span class="line"># 倒排列表(Posting List)</span><br><span class="line">&gt; 记录单词对应的文档结合</span><br><span class="line">  - 倒排索引项(Posting)</span><br><span class="line">    - 文档ID</span><br><span class="line">    - 词频TF - 单词在文档出现的次数</span><br><span class="line">    - 位置Position - 单词在文档中分词的位置，用于语句搜索 phrase query</span><br><span class="line">    - 偏移Offset - 记录单词的开始结束位置，实现高量显示</span><br></pre></td></tr></table></figure></li>
<li><p>Elasticsearch 分词器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Analysis</span><br><span class="line">  - Analysis: 文本分析是把全文本转换一系列单词 term/token的过程</span><br><span class="line">  - Analysis是通过Analyzer实现</span><br><span class="line"></span><br><span class="line"># Analyzer:</span><br><span class="line">  - Character Filters: 针对原始文本处理</span><br><span class="line">    - HTML strip - 去除html标签</span><br><span class="line">    - Mapping - 字符串替换</span><br><span class="line">    - Pattern repalce - 正则匹配替换</span><br><span class="line"></span><br><span class="line">  - Tokenizer: 将原始的文本按照一定的规则，切分为词 term or token</span><br><span class="line">    - whitespace</span><br><span class="line">    - standard</span><br><span class="line">    - uax_url_email</span><br><span class="line">    - pattern</span><br><span class="line">    - keyward</span><br><span class="line">    - path hierarchy</span><br><span class="line"></span><br><span class="line">  - Token Filter: 将切分的单词进行加工，小写，删除stopwords,增加同义词</span><br><span class="line">    - Lowercase</span><br><span class="line">    - stop</span><br><span class="line"></span><br><span class="line"># Elasticsearch内置分词器</span><br><span class="line">//默认分词器 standard</span><br><span class="line">// 按词切分，小写处理</span><br><span class="line">GET _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;standard&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//Simple Analyzer</span><br><span class="line">// 按照非字母切分，非字母被去除</span><br><span class="line">// 小写处理</span><br><span class="line">GET _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;simple&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Whitespace Analyzer</span><br><span class="line">// 按照空格切分</span><br><span class="line">GET _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;whitespace&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Stop Analyzer</span><br><span class="line">// stop filter: 去除the, a, is 修饰性词</span><br><span class="line">GET _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;stop&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//Keyward Analyzer</span><br><span class="line">//不分词，直接将输入当输出</span><br><span class="line">GET _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;keyword&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//正则表达式进行分词</span><br><span class="line">//默认非字符的符号进行分隔</span><br><span class="line">GET _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;pattern&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//english</span><br><span class="line">GET _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;english&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 running Quick brown-foxes leap over dogs in the summer evening.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// analysis_icu</span><br><span class="line">// elasticsearch-plugin install analysis_icu</span><br><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;icu_analyzer&quot;,</span><br><span class="line">  &quot;text&quot;:&quot;他说的确实在理&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>Search API</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># URI Search - 通过URI query实现搜索</span><br><span class="line">  q: 指定查询语句, 使用Query String Syntax</span><br><span class="line">  df: 默认字段, 不指定会对所有字段进行查询</span><br><span class="line">  Sort: 排序/from 和 size 用于分页</span><br><span class="line">  Profile: 查看查询是如何被执行</span><br><span class="line"></span><br><span class="line">  1. 指定字段 vs. 泛查询</span><br><span class="line">  //带profile 普通查询</span><br><span class="line">  GET /movies/_search?q=2012&amp;df=title</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;profile&quot;: &quot;true&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //带profile 泛查询</span><br><span class="line">  GET /movies/_search?q=2012</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;profile&quot;: &quot;true&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //带profile 指定字段</span><br><span class="line">  GET /movies/_search?q=title:2012</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;profile&quot;: &quot;true&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  2. Term vs. Phrase</span><br><span class="line">    # Term: Beautiful Mind 等效于 Beautiful OR Mind</span><br><span class="line">    # Phrase: &quot;Beautifuk Mind&quot; 等效于 Beautiful And Mind, 前后顺序保持一致</span><br><span class="line">  //使用引号 查询</span><br><span class="line">  GET /movies/_search?q=title:&quot;Beautiful Mind&quot;</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;profile&quot;:&quot;true&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //使用引号 Mind 泛 查询</span><br><span class="line">  GET /movies/_search?q=title:Beautiful Mind</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;profile&quot;:&quot;true&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //使用引号 Bool 泛 查询</span><br><span class="line">  GET /movies/_search?q=title:(Beautiful Mind)</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;profile&quot;:&quot;true&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  3. 布尔操作</span><br><span class="line">    AND / OR / NOT 或者 &amp;&amp; / || / !</span><br><span class="line">    title:(matrix NOT reloaded)</span><br><span class="line"></span><br><span class="line">  4. 分组</span><br><span class="line">    + 表示 must</span><br><span class="line">    - 表示 must_not</span><br><span class="line">    title:(+matrix -reloaded)</span><br><span class="line"></span><br><span class="line">  5. 范围查询</span><br><span class="line">    []闭区间 &#123;&#125;开区间</span><br><span class="line"></span><br><span class="line">  6. 算数符号</span><br><span class="line">    year:&gt;2010</span><br><span class="line"></span><br><span class="line">  7. 通配符查询(通配符查询效率低，占用内存大，不建议使用)</span><br><span class="line">    ? 代表1个字符</span><br><span class="line">    * 代表0或多个字符</span><br><span class="line"></span><br><span class="line">  8. 正则表达式</span><br><span class="line">    title:[bt]oy</span><br><span class="line"></span><br><span class="line">  9. 模糊匹配与近似查询</span><br><span class="line">    title:befutifl~1</span><br><span class="line"></span><br><span class="line"># Request Body Search</span><br><span class="line">  1. 分页:</span><br><span class="line">    from, size</span><br><span class="line"></span><br><span class="line">  2. sort:</span><br><span class="line"></span><br><span class="line">  3. _source filtering: 如果_source没有存储，就只返回匹配的文档的元数据</span><br><span class="line"></span><br><span class="line">  4. 脚本字段:</span><br><span class="line"></span><br><span class="line">  5. 查询表达式 - Match</span><br><span class="line"></span><br><span class="line">  6. Match</span><br><span class="line"></span><br><span class="line"># Page Rank算法</span><br><span class="line">  1. 衡量相关性 Information Retrieval</span><br><span class="line">    a. Precision (查准率) - 尽可能返回较少的无关文档</span><br><span class="line">    b. Recall(查全率)     - 尽量返回较多的相关文档</span><br><span class="line">    c. Ranking            - 是否能够按照相关度进行排序</span><br></pre></td></tr></table></figure></li>
<li><p>Mapping</p>
<blockquote>
<p>类似数据库中的scehma定义</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 定义索引中的字段名称</span><br><span class="line">2. 定义字段的数据类型</span><br><span class="line">Mapping 把JSON文档映射成Lucene所需要的扁平格式</span><br><span class="line">一个Mapping属于一个索引的type</span><br><span class="line"></span><br><span class="line"># 四种不同级别的Index Options - 控制倒排索引记录的内容</span><br><span class="line">  docs - 记录doc id</span><br><span class="line">  freqs - 记录 doc id 和 term frequencies</span><br><span class="line">  positions - 记录 doc id/term frequencies/term position</span><br><span class="line">  offsets - 记录 doc id/term frequencies/term position/character offsets</span><br></pre></td></tr></table></figure></li>
<li><p>数据类型<br>JSON -&gt; Elasticsearch类型</p>
<table>
<thead>
<tr>
<th align="left">JSON类型</th>
<th align="left">Elasticsearch 类型</th>
</tr>
</thead>
<tbody><tr>
<td align="left">字符串</td>
<td align="left">匹配日期格式 -&gt; Date</td>
</tr>
<tr>
<td align="left">布尔值</td>
<td align="left">boolean</td>
</tr>
<tr>
<td align="left">浮点数</td>
<td align="left">float</td>
</tr>
<tr>
<td align="left">整数</td>
<td align="left">long</td>
</tr>
<tr>
<td align="left">对象</td>
<td align="left">Object</td>
</tr>
<tr>
<td align="left">数组</td>
<td align="left">由第一个非空数值的类型所决定</td>
</tr>
<tr>
<td align="left">空值</td>
<td align="left">忽略</td>
</tr>
</tbody></table>
</li>
</ul>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 简单类型:</span><br><span class="line">  1. Text/Keyword</span><br><span class="line">  2. Date</span><br><span class="line">  3. Integer / Floating</span><br><span class="line">  4. Boolean</span><br><span class="line">  5. IPv4 &amp; IPv6</span><br><span class="line"></span><br><span class="line"># 复杂类型 - 对象和嵌套对象</span><br><span class="line">  对象类型/嵌套类型</span><br><span class="line"></span><br><span class="line"># 特殊类型</span><br><span class="line">  geo_point &amp; geo_shape / percolator</span><br></pre></td></tr></table></figure>

<h2 id="Elasticsearch-聚合-Aggregation"><a href="#Elasticsearch-聚合-Aggregation" class="headerlink" title="Elasticsearch 聚合 (Aggregation)"></a>Elasticsearch 聚合 (Aggregation)</h2><blockquote>
<p>Elasticsearch 除了搜索以外还提供针对ES数据进行统计分析</p>
</blockquote>
<ul>
<li>集合分类<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. Bucket Aggregation: 满足特定条件的文档集合</span><br><span class="line">  group by</span><br><span class="line"></span><br><span class="line">2. Metric Aggregation: 数学运算，对文档字段统计分析</span><br><span class="line">  min/max/sum/avg/cardinality</span><br><span class="line"></span><br><span class="line">3. Pipeline Aggregation: 对聚合结果进行二次聚合</span><br><span class="line">4. Matrix Aggregation: 支持多个字段的操作并提供结果矩阵</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Elasticsearch-分布式结构"><a href="#Elasticsearch-分布式结构" class="headerlink" title="Elasticsearch 分布式结构"></a>Elasticsearch 分布式结构</h2><ul>
<li><p>高可用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 服务可用性 - 允许有节点停止服务</span><br><span class="line">2. 数据可用性 - 部分节点丢失，不会丢失数据</span><br></pre></td></tr></table></figure></li>
<li><p>可扩展性</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 请求量提升/数据不断增加(将数据分布到所有节点上)</span><br></pre></td></tr></table></figure></li>
<li><p>Elasticsearch分布式架构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 不同的集群通过不同的名字区分，-E cluster.name=geektime</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="ELK-大数据分析"><a href="#ELK-大数据分析" class="headerlink" title="ELK 大数据分析"></a>ELK 大数据分析</h2>]]></content>
      <tags>
        <tag>搜索引擎</tag>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title>golang pkg Tips &amp; Tracks</title>
    <url>/2021/09/03/golang-pkg-Tips-Tracks/</url>
    <content><![CDATA[<h1 id="Golang"><a href="#Golang" class="headerlink" title="Golang"></a>Golang</h1><span id="more"></span>

<h2 id="Golang-Tips-amp-Tracks"><a href="#Golang-Tips-amp-Tracks" class="headerlink" title="Golang Tips &amp; Tracks"></a>Golang Tips &amp; Tracks</h2><ul>
<li><strong>负载均衡算法对比</strong><blockquote>
<p>负载均衡最重要的就是均衡</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">  &quot;fmt&quot;</span><br><span class="line">  &quot;math/rand&quot;</span><br><span class="line">  &quot;time&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func init() &#123;</span><br><span class="line">  rand.Seed(time.Now().UnixNano())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func normal_shuffle(slice []int) &#123;</span><br><span class="line">  for i := 0; i &lt; len(slice); i++ &#123;</span><br><span class="line">    a := rand.Intn(len(slice))</span><br><span class="line">    b := rand.Intn(len(slice))</span><br><span class="line">    slice[a], slice[b] = slice[b], slice[a]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func shuffle(indexes []int) &#123;</span><br><span class="line">  for i := len(indexes); i &gt; 0; i-- &#123;</span><br><span class="line">    lastIdx := i - 1</span><br><span class="line">    idx := rand.Intn(i)</span><br><span class="line">    indexes[lastIdx], indexes[idx] = indexes[idx], indexes[lastIdx]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">  var cnt1 = map[int]int&#123;&#125;</span><br><span class="line">  for i := 0; i &lt; 1000000; i++ &#123;</span><br><span class="line">    var sl = []int&#123;0, 1, 2, 3, 4, 5, 6&#125;</span><br><span class="line">    normal_shuffle(sl)</span><br><span class="line">    cnt1[sl[0]]++</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  var cnt2 = map[int]int&#123;&#125;</span><br><span class="line">  for i := 0; i &lt; 1000000; i++ &#123;</span><br><span class="line">    var sl = []int&#123;0, 1, 2, 3, 4, 5, 6&#125;</span><br><span class="line">    shuffle(sl)</span><br><span class="line">    cnt2[sl[0]]++</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  fmt.Println(&quot;normal shuffle: &quot;, cnt1)</span><br><span class="line">  fmt.Println(&quot;fisher yates  : &quot;, cnt2)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">chyi/go-awesome-prj/shuffle via 🐹 v1.17 took 38s</span><br><span class="line">➜ go run main.go</span><br><span class="line">normal shuffle:  map[0:224558 1:128887 2:129201 3:129493 4:129487 5:129202 6:129172]</span><br><span class="line">fisher yates  :  map[0:142974 1:143116 2:142768 3:142660 4:142930 5:142505 6:143047]</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
</search>
